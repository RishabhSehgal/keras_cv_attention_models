{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "#import pandas as pd\n",
    "#import matplotlib.pyplot as plt\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-06 22:21:26.333543: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-04-06 22:21:27.725420: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 46577 MB memory:  -> device: 1, name: Quadro RTX 8000, pci bus id: 0000:1a:00.0, compute capability: 7.5\n",
      "2022-04-06 22:21:27.727312: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 46579 MB memory:  -> device: 2, name: Quadro RTX 8000, pci bus id: 0000:67:00.0, compute capability: 7.5\n",
      "2022-04-06 22:21:27.729281: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:2 with 46576 MB memory:  -> device: 3, name: Quadro RTX 8000, pci bus id: 0000:68:00.0, compute capability: 7.5\n"
     ]
    }
   ],
   "source": [
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "try:\n",
    "  # Disable first GPU\n",
    "  tf.config.set_visible_devices(physical_devices[1:], 'GPU')\n",
    "  logical_devices = tf.config.list_logical_devices('GPU')\n",
    "  # Logical device was not created for first GPU\n",
    "  assert len(logical_devices) == len(physical_devices) - 1\n",
    "except:\n",
    "  # Invalid device or cannot modify virtual devices once initialized.\n",
    "  pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/local/lambda/rishabhs/anaconda3/envs/cloned_tf2.8-cudnn8.1-cudadev-11.2-py3.8/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>>> Load pretrained from: /home/local/lambda/rishabhs/ML/keras_cv_attention_models/checkpoints_bkup_finetunedcifar10/effv2b0_cifar10_224_progressive_epoch_35_val_acc_0.9528.h5\n",
      "Model: \"efficientnet_v2-b0\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 224, 224, 3  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " stem_conv (Conv2D)             (None, 112, 112, 32  864         ['input_1[0][0]']                \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " stem_bn (BatchNormalization)   (None, 112, 112, 32  128         ['stem_conv[0][0]']              \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " stem_swish (Activation)        (None, 112, 112, 32  0           ['stem_bn[0][0]']                \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " stack_0_block0_fu_conv (Conv2D  (None, 112, 112, 16  4608       ['stem_swish[0][0]']             \n",
      " )                              )                                                                 \n",
      "                                                                                                  \n",
      " stack_0_block0_fu_bn (BatchNor  (None, 112, 112, 16  64         ['stack_0_block0_fu_conv[0][0]'] \n",
      " malization)                    )                                                                 \n",
      "                                                                                                  \n",
      " stack_0_block0_fu_swish (Activ  (None, 112, 112, 16  0          ['stack_0_block0_fu_bn[0][0]']   \n",
      " ation)                         )                                                                 \n",
      "                                                                                                  \n",
      " stack_0_block0_output (Activat  (None, 112, 112, 16  0          ['stack_0_block0_fu_swish[0][0]']\n",
      " ion)                           )                                                                 \n",
      "                                                                                                  \n",
      " stack_1_block0_sortcut_conv (C  (None, 56, 56, 64)  9216        ['stack_0_block0_output[0][0]']  \n",
      " onv2D)                                                                                           \n",
      "                                                                                                  \n",
      " stack_1_block0_sortcut_bn (Bat  (None, 56, 56, 64)  256         ['stack_1_block0_sortcut_conv[0][\n",
      " chNormalization)                                                0]']                             \n",
      "                                                                                                  \n",
      " stack_1_block0_sortcut_swish (  (None, 56, 56, 64)  0           ['stack_1_block0_sortcut_bn[0][0]\n",
      " Activation)                                                     ']                               \n",
      "                                                                                                  \n",
      " stack_1_block0_MB_pw_conv (Con  (None, 56, 56, 32)  2048        ['stack_1_block0_sortcut_swish[0]\n",
      " v2D)                                                            [0]']                            \n",
      "                                                                                                  \n",
      " stack_1_block0_MB_pw_bn (Batch  (None, 56, 56, 32)  128         ['stack_1_block0_MB_pw_conv[0][0]\n",
      " Normalization)                                                  ']                               \n",
      "                                                                                                  \n",
      " stack_1_block0_output (Activat  (None, 56, 56, 32)  0           ['stack_1_block0_MB_pw_bn[0][0]']\n",
      " ion)                                                                                             \n",
      "                                                                                                  \n",
      " stack_1_block1_sortcut_conv (C  (None, 56, 56, 128)  36864      ['stack_1_block0_output[0][0]']  \n",
      " onv2D)                                                                                           \n",
      "                                                                                                  \n",
      " stack_1_block1_sortcut_bn (Bat  (None, 56, 56, 128)  512        ['stack_1_block1_sortcut_conv[0][\n",
      " chNormalization)                                                0]']                             \n",
      "                                                                                                  \n",
      " stack_1_block1_sortcut_swish (  (None, 56, 56, 128)  0          ['stack_1_block1_sortcut_bn[0][0]\n",
      " Activation)                                                     ']                               \n",
      "                                                                                                  \n",
      " stack_1_block1_MB_pw_conv (Con  (None, 56, 56, 32)  4096        ['stack_1_block1_sortcut_swish[0]\n",
      " v2D)                                                            [0]']                            \n",
      "                                                                                                  \n",
      " stack_1_block1_MB_pw_bn (Batch  (None, 56, 56, 32)  128         ['stack_1_block1_MB_pw_conv[0][0]\n",
      " Normalization)                                                  ']                               \n",
      "                                                                                                  \n",
      " stack_1_block1_output (Add)    (None, 56, 56, 32)   0           ['stack_1_block0_output[0][0]',  \n",
      "                                                                  'stack_1_block1_MB_pw_bn[0][0]']\n",
      "                                                                                                  \n",
      " stack_2_block0_sortcut_conv (C  (None, 28, 28, 128)  36864      ['stack_1_block1_output[0][0]']  \n",
      " onv2D)                                                                                           \n",
      "                                                                                                  \n",
      " stack_2_block0_sortcut_bn (Bat  (None, 28, 28, 128)  512        ['stack_2_block0_sortcut_conv[0][\n",
      " chNormalization)                                                0]']                             \n",
      "                                                                                                  \n",
      " stack_2_block0_sortcut_swish (  (None, 28, 28, 128)  0          ['stack_2_block0_sortcut_bn[0][0]\n",
      " Activation)                                                     ']                               \n",
      "                                                                                                  \n",
      " stack_2_block0_MB_pw_conv (Con  (None, 28, 28, 48)  6144        ['stack_2_block0_sortcut_swish[0]\n",
      " v2D)                                                            [0]']                            \n",
      "                                                                                                  \n",
      " stack_2_block0_MB_pw_bn (Batch  (None, 28, 28, 48)  192         ['stack_2_block0_MB_pw_conv[0][0]\n",
      " Normalization)                                                  ']                               \n",
      "                                                                                                  \n",
      " stack_2_block0_output (Activat  (None, 28, 28, 48)  0           ['stack_2_block0_MB_pw_bn[0][0]']\n",
      " ion)                                                                                             \n",
      "                                                                                                  \n",
      " stack_2_block1_sortcut_conv (C  (None, 28, 28, 192)  82944      ['stack_2_block0_output[0][0]']  \n",
      " onv2D)                                                                                           \n",
      "                                                                                                  \n",
      " stack_2_block1_sortcut_bn (Bat  (None, 28, 28, 192)  768        ['stack_2_block1_sortcut_conv[0][\n",
      " chNormalization)                                                0]']                             \n",
      "                                                                                                  \n",
      " stack_2_block1_sortcut_swish (  (None, 28, 28, 192)  0          ['stack_2_block1_sortcut_bn[0][0]\n",
      " Activation)                                                     ']                               \n",
      "                                                                                                  \n",
      " stack_2_block1_MB_pw_conv (Con  (None, 28, 28, 48)  9216        ['stack_2_block1_sortcut_swish[0]\n",
      " v2D)                                                            [0]']                            \n",
      "                                                                                                  \n",
      " stack_2_block1_MB_pw_bn (Batch  (None, 28, 28, 48)  192         ['stack_2_block1_MB_pw_conv[0][0]\n",
      " Normalization)                                                  ']                               \n",
      "                                                                                                  \n",
      " stack_2_block1_output (Add)    (None, 28, 28, 48)   0           ['stack_2_block0_output[0][0]',  \n",
      "                                                                  'stack_2_block1_MB_pw_bn[0][0]']\n",
      "                                                                                                  \n",
      " stack_3_block0_sortcut_conv (C  (None, 28, 28, 192)  9216       ['stack_2_block1_output[0][0]']  \n",
      " onv2D)                                                                                           \n",
      "                                                                                                  \n",
      " stack_3_block0_sortcut_bn (Bat  (None, 28, 28, 192)  768        ['stack_3_block0_sortcut_conv[0][\n",
      " chNormalization)                                                0]']                             \n",
      "                                                                                                  \n",
      " stack_3_block0_sortcut_swish (  (None, 28, 28, 192)  0          ['stack_3_block0_sortcut_bn[0][0]\n",
      " Activation)                                                     ']                               \n",
      "                                                                                                  \n",
      " stack_3_block0_MB_dw_ (Depthwi  (None, 14, 14, 192)  1728       ['stack_3_block0_sortcut_swish[0]\n",
      " seConv2D)                                                       [0]']                            \n",
      "                                                                                                  \n",
      " stack_3_block0_MB_dw_bn (Batch  (None, 14, 14, 192)  768        ['stack_3_block0_MB_dw_[0][0]']  \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " stack_3_block0_MB_dw_swish (Ac  (None, 14, 14, 192)  0          ['stack_3_block0_MB_dw_bn[0][0]']\n",
      " tivation)                                                                                        \n",
      "                                                                                                  \n",
      " tf.math.reduce_mean (TFOpLambd  (None, 1, 1, 192)   0           ['stack_3_block0_MB_dw_swish[0][0\n",
      " a)                                                              ]']                              \n",
      "                                                                                                  \n",
      " stack_3_block0_se_1_conv (Conv  (None, 1, 1, 12)    2316        ['tf.math.reduce_mean[0][0]']    \n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " stack_3_block0_se_swish (Activ  (None, 1, 1, 12)    0           ['stack_3_block0_se_1_conv[0][0]'\n",
      " ation)                                                          ]                                \n",
      "                                                                                                  \n",
      " stack_3_block0_se_2_conv (Conv  (None, 1, 1, 192)   2496        ['stack_3_block0_se_swish[0][0]']\n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " stack_3_block0_se_sigmoid (Act  (None, 1, 1, 192)   0           ['stack_3_block0_se_2_conv[0][0]'\n",
      " ivation)                                                        ]                                \n",
      "                                                                                                  \n",
      " stack_3_block0_se_out (Multipl  (None, 14, 14, 192)  0          ['stack_3_block0_MB_dw_swish[0][0\n",
      " y)                                                              ]',                              \n",
      "                                                                  'stack_3_block0_se_sigmoid[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " stack_3_block0_MB_pw_conv (Con  (None, 14, 14, 96)  18432       ['stack_3_block0_se_out[0][0]']  \n",
      " v2D)                                                                                             \n",
      "                                                                                                  \n",
      " stack_3_block0_MB_pw_bn (Batch  (None, 14, 14, 96)  384         ['stack_3_block0_MB_pw_conv[0][0]\n",
      " Normalization)                                                  ']                               \n",
      "                                                                                                  \n",
      " stack_3_block0_output (Activat  (None, 14, 14, 96)  0           ['stack_3_block0_MB_pw_bn[0][0]']\n",
      " ion)                                                                                             \n",
      "                                                                                                  \n",
      " stack_3_block1_sortcut_conv (C  (None, 14, 14, 384)  36864      ['stack_3_block0_output[0][0]']  \n",
      " onv2D)                                                                                           \n",
      "                                                                                                  \n",
      " stack_3_block1_sortcut_bn (Bat  (None, 14, 14, 384)  1536       ['stack_3_block1_sortcut_conv[0][\n",
      " chNormalization)                                                0]']                             \n",
      "                                                                                                  \n",
      " stack_3_block1_sortcut_swish (  (None, 14, 14, 384)  0          ['stack_3_block1_sortcut_bn[0][0]\n",
      " Activation)                                                     ']                               \n",
      "                                                                                                  \n",
      " stack_3_block1_MB_dw_ (Depthwi  (None, 14, 14, 384)  3456       ['stack_3_block1_sortcut_swish[0]\n",
      " seConv2D)                                                       [0]']                            \n",
      "                                                                                                  \n",
      " stack_3_block1_MB_dw_bn (Batch  (None, 14, 14, 384)  1536       ['stack_3_block1_MB_dw_[0][0]']  \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " stack_3_block1_MB_dw_swish (Ac  (None, 14, 14, 384)  0          ['stack_3_block1_MB_dw_bn[0][0]']\n",
      " tivation)                                                                                        \n",
      "                                                                                                  \n",
      " tf.math.reduce_mean_1 (TFOpLam  (None, 1, 1, 384)   0           ['stack_3_block1_MB_dw_swish[0][0\n",
      " bda)                                                            ]']                              \n",
      "                                                                                                  \n",
      " stack_3_block1_se_1_conv (Conv  (None, 1, 1, 24)    9240        ['tf.math.reduce_mean_1[0][0]']  \n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " stack_3_block1_se_swish (Activ  (None, 1, 1, 24)    0           ['stack_3_block1_se_1_conv[0][0]'\n",
      " ation)                                                          ]                                \n",
      "                                                                                                  \n",
      " stack_3_block1_se_2_conv (Conv  (None, 1, 1, 384)   9600        ['stack_3_block1_se_swish[0][0]']\n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " stack_3_block1_se_sigmoid (Act  (None, 1, 1, 384)   0           ['stack_3_block1_se_2_conv[0][0]'\n",
      " ivation)                                                        ]                                \n",
      "                                                                                                  \n",
      " stack_3_block1_se_out (Multipl  (None, 14, 14, 384)  0          ['stack_3_block1_MB_dw_swish[0][0\n",
      " y)                                                              ]',                              \n",
      "                                                                  'stack_3_block1_se_sigmoid[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " stack_3_block1_MB_pw_conv (Con  (None, 14, 14, 96)  36864       ['stack_3_block1_se_out[0][0]']  \n",
      " v2D)                                                                                             \n",
      "                                                                                                  \n",
      " stack_3_block1_MB_pw_bn (Batch  (None, 14, 14, 96)  384         ['stack_3_block1_MB_pw_conv[0][0]\n",
      " Normalization)                                                  ']                               \n",
      "                                                                                                  \n",
      " stack_3_block1_output (Add)    (None, 14, 14, 96)   0           ['stack_3_block0_output[0][0]',  \n",
      "                                                                  'stack_3_block1_MB_pw_bn[0][0]']\n",
      "                                                                                                  \n",
      " stack_3_block2_sortcut_conv (C  (None, 14, 14, 384)  36864      ['stack_3_block1_output[0][0]']  \n",
      " onv2D)                                                                                           \n",
      "                                                                                                  \n",
      " stack_3_block2_sortcut_bn (Bat  (None, 14, 14, 384)  1536       ['stack_3_block2_sortcut_conv[0][\n",
      " chNormalization)                                                0]']                             \n",
      "                                                                                                  \n",
      " stack_3_block2_sortcut_swish (  (None, 14, 14, 384)  0          ['stack_3_block2_sortcut_bn[0][0]\n",
      " Activation)                                                     ']                               \n",
      "                                                                                                  \n",
      " stack_3_block2_MB_dw_ (Depthwi  (None, 14, 14, 384)  3456       ['stack_3_block2_sortcut_swish[0]\n",
      " seConv2D)                                                       [0]']                            \n",
      "                                                                                                  \n",
      " stack_3_block2_MB_dw_bn (Batch  (None, 14, 14, 384)  1536       ['stack_3_block2_MB_dw_[0][0]']  \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " stack_3_block2_MB_dw_swish (Ac  (None, 14, 14, 384)  0          ['stack_3_block2_MB_dw_bn[0][0]']\n",
      " tivation)                                                                                        \n",
      "                                                                                                  \n",
      " tf.math.reduce_mean_2 (TFOpLam  (None, 1, 1, 384)   0           ['stack_3_block2_MB_dw_swish[0][0\n",
      " bda)                                                            ]']                              \n",
      "                                                                                                  \n",
      " stack_3_block2_se_1_conv (Conv  (None, 1, 1, 24)    9240        ['tf.math.reduce_mean_2[0][0]']  \n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " stack_3_block2_se_swish (Activ  (None, 1, 1, 24)    0           ['stack_3_block2_se_1_conv[0][0]'\n",
      " ation)                                                          ]                                \n",
      "                                                                                                  \n",
      " stack_3_block2_se_2_conv (Conv  (None, 1, 1, 384)   9600        ['stack_3_block2_se_swish[0][0]']\n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " stack_3_block2_se_sigmoid (Act  (None, 1, 1, 384)   0           ['stack_3_block2_se_2_conv[0][0]'\n",
      " ivation)                                                        ]                                \n",
      "                                                                                                  \n",
      " stack_3_block2_se_out (Multipl  (None, 14, 14, 384)  0          ['stack_3_block2_MB_dw_swish[0][0\n",
      " y)                                                              ]',                              \n",
      "                                                                  'stack_3_block2_se_sigmoid[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " stack_3_block2_MB_pw_conv (Con  (None, 14, 14, 96)  36864       ['stack_3_block2_se_out[0][0]']  \n",
      " v2D)                                                                                             \n",
      "                                                                                                  \n",
      " stack_3_block2_MB_pw_bn (Batch  (None, 14, 14, 96)  384         ['stack_3_block2_MB_pw_conv[0][0]\n",
      " Normalization)                                                  ']                               \n",
      "                                                                                                  \n",
      " stack_3_block2_output (Add)    (None, 14, 14, 96)   0           ['stack_3_block1_output[0][0]',  \n",
      "                                                                  'stack_3_block2_MB_pw_bn[0][0]']\n",
      "                                                                                                  \n",
      " stack_4_block0_sortcut_conv (C  (None, 14, 14, 576)  55296      ['stack_3_block2_output[0][0]']  \n",
      " onv2D)                                                                                           \n",
      "                                                                                                  \n",
      " stack_4_block0_sortcut_bn (Bat  (None, 14, 14, 576)  2304       ['stack_4_block0_sortcut_conv[0][\n",
      " chNormalization)                                                0]']                             \n",
      "                                                                                                  \n",
      " stack_4_block0_sortcut_swish (  (None, 14, 14, 576)  0          ['stack_4_block0_sortcut_bn[0][0]\n",
      " Activation)                                                     ']                               \n",
      "                                                                                                  \n",
      " stack_4_block0_MB_dw_ (Depthwi  (None, 14, 14, 576)  5184       ['stack_4_block0_sortcut_swish[0]\n",
      " seConv2D)                                                       [0]']                            \n",
      "                                                                                                  \n",
      " stack_4_block0_MB_dw_bn (Batch  (None, 14, 14, 576)  2304       ['stack_4_block0_MB_dw_[0][0]']  \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " stack_4_block0_MB_dw_swish (Ac  (None, 14, 14, 576)  0          ['stack_4_block0_MB_dw_bn[0][0]']\n",
      " tivation)                                                                                        \n",
      "                                                                                                  \n",
      " tf.math.reduce_mean_3 (TFOpLam  (None, 1, 1, 576)   0           ['stack_4_block0_MB_dw_swish[0][0\n",
      " bda)                                                            ]']                              \n",
      "                                                                                                  \n",
      " stack_4_block0_se_1_conv (Conv  (None, 1, 1, 24)    13848       ['tf.math.reduce_mean_3[0][0]']  \n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " stack_4_block0_se_swish (Activ  (None, 1, 1, 24)    0           ['stack_4_block0_se_1_conv[0][0]'\n",
      " ation)                                                          ]                                \n",
      "                                                                                                  \n",
      " stack_4_block0_se_2_conv (Conv  (None, 1, 1, 576)   14400       ['stack_4_block0_se_swish[0][0]']\n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " stack_4_block0_se_sigmoid (Act  (None, 1, 1, 576)   0           ['stack_4_block0_se_2_conv[0][0]'\n",
      " ivation)                                                        ]                                \n",
      "                                                                                                  \n",
      " stack_4_block0_se_out (Multipl  (None, 14, 14, 576)  0          ['stack_4_block0_MB_dw_swish[0][0\n",
      " y)                                                              ]',                              \n",
      "                                                                  'stack_4_block0_se_sigmoid[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " stack_4_block0_MB_pw_conv (Con  (None, 14, 14, 112)  64512      ['stack_4_block0_se_out[0][0]']  \n",
      " v2D)                                                                                             \n",
      "                                                                                                  \n",
      " stack_4_block0_MB_pw_bn (Batch  (None, 14, 14, 112)  448        ['stack_4_block0_MB_pw_conv[0][0]\n",
      " Normalization)                                                  ']                               \n",
      "                                                                                                  \n",
      " stack_4_block0_output (Activat  (None, 14, 14, 112)  0          ['stack_4_block0_MB_pw_bn[0][0]']\n",
      " ion)                                                                                             \n",
      "                                                                                                  \n",
      " stack_4_block1_sortcut_conv (C  (None, 14, 14, 672)  75264      ['stack_4_block0_output[0][0]']  \n",
      " onv2D)                                                                                           \n",
      "                                                                                                  \n",
      " stack_4_block1_sortcut_bn (Bat  (None, 14, 14, 672)  2688       ['stack_4_block1_sortcut_conv[0][\n",
      " chNormalization)                                                0]']                             \n",
      "                                                                                                  \n",
      " stack_4_block1_sortcut_swish (  (None, 14, 14, 672)  0          ['stack_4_block1_sortcut_bn[0][0]\n",
      " Activation)                                                     ']                               \n",
      "                                                                                                  \n",
      " stack_4_block1_MB_dw_ (Depthwi  (None, 14, 14, 672)  6048       ['stack_4_block1_sortcut_swish[0]\n",
      " seConv2D)                                                       [0]']                            \n",
      "                                                                                                  \n",
      " stack_4_block1_MB_dw_bn (Batch  (None, 14, 14, 672)  2688       ['stack_4_block1_MB_dw_[0][0]']  \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " stack_4_block1_MB_dw_swish (Ac  (None, 14, 14, 672)  0          ['stack_4_block1_MB_dw_bn[0][0]']\n",
      " tivation)                                                                                        \n",
      "                                                                                                  \n",
      " tf.math.reduce_mean_4 (TFOpLam  (None, 1, 1, 672)   0           ['stack_4_block1_MB_dw_swish[0][0\n",
      " bda)                                                            ]']                              \n",
      "                                                                                                  \n",
      " stack_4_block1_se_1_conv (Conv  (None, 1, 1, 28)    18844       ['tf.math.reduce_mean_4[0][0]']  \n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " stack_4_block1_se_swish (Activ  (None, 1, 1, 28)    0           ['stack_4_block1_se_1_conv[0][0]'\n",
      " ation)                                                          ]                                \n",
      "                                                                                                  \n",
      " stack_4_block1_se_2_conv (Conv  (None, 1, 1, 672)   19488       ['stack_4_block1_se_swish[0][0]']\n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " stack_4_block1_se_sigmoid (Act  (None, 1, 1, 672)   0           ['stack_4_block1_se_2_conv[0][0]'\n",
      " ivation)                                                        ]                                \n",
      "                                                                                                  \n",
      " stack_4_block1_se_out (Multipl  (None, 14, 14, 672)  0          ['stack_4_block1_MB_dw_swish[0][0\n",
      " y)                                                              ]',                              \n",
      "                                                                  'stack_4_block1_se_sigmoid[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " stack_4_block1_MB_pw_conv (Con  (None, 14, 14, 112)  75264      ['stack_4_block1_se_out[0][0]']  \n",
      " v2D)                                                                                             \n",
      "                                                                                                  \n",
      " stack_4_block1_MB_pw_bn (Batch  (None, 14, 14, 112)  448        ['stack_4_block1_MB_pw_conv[0][0]\n",
      " Normalization)                                                  ']                               \n",
      "                                                                                                  \n",
      " stack_4_block1_output (Add)    (None, 14, 14, 112)  0           ['stack_4_block0_output[0][0]',  \n",
      "                                                                  'stack_4_block1_MB_pw_bn[0][0]']\n",
      "                                                                                                  \n",
      " stack_4_block2_sortcut_conv (C  (None, 14, 14, 672)  75264      ['stack_4_block1_output[0][0]']  \n",
      " onv2D)                                                                                           \n",
      "                                                                                                  \n",
      " stack_4_block2_sortcut_bn (Bat  (None, 14, 14, 672)  2688       ['stack_4_block2_sortcut_conv[0][\n",
      " chNormalization)                                                0]']                             \n",
      "                                                                                                  \n",
      " stack_4_block2_sortcut_swish (  (None, 14, 14, 672)  0          ['stack_4_block2_sortcut_bn[0][0]\n",
      " Activation)                                                     ']                               \n",
      "                                                                                                  \n",
      " stack_4_block2_MB_dw_ (Depthwi  (None, 14, 14, 672)  6048       ['stack_4_block2_sortcut_swish[0]\n",
      " seConv2D)                                                       [0]']                            \n",
      "                                                                                                  \n",
      " stack_4_block2_MB_dw_bn (Batch  (None, 14, 14, 672)  2688       ['stack_4_block2_MB_dw_[0][0]']  \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " stack_4_block2_MB_dw_swish (Ac  (None, 14, 14, 672)  0          ['stack_4_block2_MB_dw_bn[0][0]']\n",
      " tivation)                                                                                        \n",
      "                                                                                                  \n",
      " tf.math.reduce_mean_5 (TFOpLam  (None, 1, 1, 672)   0           ['stack_4_block2_MB_dw_swish[0][0\n",
      " bda)                                                            ]']                              \n",
      "                                                                                                  \n",
      " stack_4_block2_se_1_conv (Conv  (None, 1, 1, 28)    18844       ['tf.math.reduce_mean_5[0][0]']  \n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " stack_4_block2_se_swish (Activ  (None, 1, 1, 28)    0           ['stack_4_block2_se_1_conv[0][0]'\n",
      " ation)                                                          ]                                \n",
      "                                                                                                  \n",
      " stack_4_block2_se_2_conv (Conv  (None, 1, 1, 672)   19488       ['stack_4_block2_se_swish[0][0]']\n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " stack_4_block2_se_sigmoid (Act  (None, 1, 1, 672)   0           ['stack_4_block2_se_2_conv[0][0]'\n",
      " ivation)                                                        ]                                \n",
      "                                                                                                  \n",
      " stack_4_block2_se_out (Multipl  (None, 14, 14, 672)  0          ['stack_4_block2_MB_dw_swish[0][0\n",
      " y)                                                              ]',                              \n",
      "                                                                  'stack_4_block2_se_sigmoid[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " stack_4_block2_MB_pw_conv (Con  (None, 14, 14, 112)  75264      ['stack_4_block2_se_out[0][0]']  \n",
      " v2D)                                                                                             \n",
      "                                                                                                  \n",
      " stack_4_block2_MB_pw_bn (Batch  (None, 14, 14, 112)  448        ['stack_4_block2_MB_pw_conv[0][0]\n",
      " Normalization)                                                  ']                               \n",
      "                                                                                                  \n",
      " stack_4_block2_output (Add)    (None, 14, 14, 112)  0           ['stack_4_block1_output[0][0]',  \n",
      "                                                                  'stack_4_block2_MB_pw_bn[0][0]']\n",
      "                                                                                                  \n",
      " stack_4_block3_sortcut_conv (C  (None, 14, 14, 672)  75264      ['stack_4_block2_output[0][0]']  \n",
      " onv2D)                                                                                           \n",
      "                                                                                                  \n",
      " stack_4_block3_sortcut_bn (Bat  (None, 14, 14, 672)  2688       ['stack_4_block3_sortcut_conv[0][\n",
      " chNormalization)                                                0]']                             \n",
      "                                                                                                  \n",
      " stack_4_block3_sortcut_swish (  (None, 14, 14, 672)  0          ['stack_4_block3_sortcut_bn[0][0]\n",
      " Activation)                                                     ']                               \n",
      "                                                                                                  \n",
      " stack_4_block3_MB_dw_ (Depthwi  (None, 14, 14, 672)  6048       ['stack_4_block3_sortcut_swish[0]\n",
      " seConv2D)                                                       [0]']                            \n",
      "                                                                                                  \n",
      " stack_4_block3_MB_dw_bn (Batch  (None, 14, 14, 672)  2688       ['stack_4_block3_MB_dw_[0][0]']  \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " stack_4_block3_MB_dw_swish (Ac  (None, 14, 14, 672)  0          ['stack_4_block3_MB_dw_bn[0][0]']\n",
      " tivation)                                                                                        \n",
      "                                                                                                  \n",
      " tf.math.reduce_mean_6 (TFOpLam  (None, 1, 1, 672)   0           ['stack_4_block3_MB_dw_swish[0][0\n",
      " bda)                                                            ]']                              \n",
      "                                                                                                  \n",
      " stack_4_block3_se_1_conv (Conv  (None, 1, 1, 28)    18844       ['tf.math.reduce_mean_6[0][0]']  \n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " stack_4_block3_se_swish (Activ  (None, 1, 1, 28)    0           ['stack_4_block3_se_1_conv[0][0]'\n",
      " ation)                                                          ]                                \n",
      "                                                                                                  \n",
      " stack_4_block3_se_2_conv (Conv  (None, 1, 1, 672)   19488       ['stack_4_block3_se_swish[0][0]']\n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " stack_4_block3_se_sigmoid (Act  (None, 1, 1, 672)   0           ['stack_4_block3_se_2_conv[0][0]'\n",
      " ivation)                                                        ]                                \n",
      "                                                                                                  \n",
      " stack_4_block3_se_out (Multipl  (None, 14, 14, 672)  0          ['stack_4_block3_MB_dw_swish[0][0\n",
      " y)                                                              ]',                              \n",
      "                                                                  'stack_4_block3_se_sigmoid[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " stack_4_block3_MB_pw_conv (Con  (None, 14, 14, 112)  75264      ['stack_4_block3_se_out[0][0]']  \n",
      " v2D)                                                                                             \n",
      "                                                                                                  \n",
      " stack_4_block3_MB_pw_bn (Batch  (None, 14, 14, 112)  448        ['stack_4_block3_MB_pw_conv[0][0]\n",
      " Normalization)                                                  ']                               \n",
      "                                                                                                  \n",
      " stack_4_block3_output (Add)    (None, 14, 14, 112)  0           ['stack_4_block2_output[0][0]',  \n",
      "                                                                  'stack_4_block3_MB_pw_bn[0][0]']\n",
      "                                                                                                  \n",
      " stack_4_block4_sortcut_conv (C  (None, 14, 14, 672)  75264      ['stack_4_block3_output[0][0]']  \n",
      " onv2D)                                                                                           \n",
      "                                                                                                  \n",
      " stack_4_block4_sortcut_bn (Bat  (None, 14, 14, 672)  2688       ['stack_4_block4_sortcut_conv[0][\n",
      " chNormalization)                                                0]']                             \n",
      "                                                                                                  \n",
      " stack_4_block4_sortcut_swish (  (None, 14, 14, 672)  0          ['stack_4_block4_sortcut_bn[0][0]\n",
      " Activation)                                                     ']                               \n",
      "                                                                                                  \n",
      " stack_4_block4_MB_dw_ (Depthwi  (None, 14, 14, 672)  6048       ['stack_4_block4_sortcut_swish[0]\n",
      " seConv2D)                                                       [0]']                            \n",
      "                                                                                                  \n",
      " stack_4_block4_MB_dw_bn (Batch  (None, 14, 14, 672)  2688       ['stack_4_block4_MB_dw_[0][0]']  \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " stack_4_block4_MB_dw_swish (Ac  (None, 14, 14, 672)  0          ['stack_4_block4_MB_dw_bn[0][0]']\n",
      " tivation)                                                                                        \n",
      "                                                                                                  \n",
      " tf.math.reduce_mean_7 (TFOpLam  (None, 1, 1, 672)   0           ['stack_4_block4_MB_dw_swish[0][0\n",
      " bda)                                                            ]']                              \n",
      "                                                                                                  \n",
      " stack_4_block4_se_1_conv (Conv  (None, 1, 1, 28)    18844       ['tf.math.reduce_mean_7[0][0]']  \n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " stack_4_block4_se_swish (Activ  (None, 1, 1, 28)    0           ['stack_4_block4_se_1_conv[0][0]'\n",
      " ation)                                                          ]                                \n",
      "                                                                                                  \n",
      " stack_4_block4_se_2_conv (Conv  (None, 1, 1, 672)   19488       ['stack_4_block4_se_swish[0][0]']\n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " stack_4_block4_se_sigmoid (Act  (None, 1, 1, 672)   0           ['stack_4_block4_se_2_conv[0][0]'\n",
      " ivation)                                                        ]                                \n",
      "                                                                                                  \n",
      " stack_4_block4_se_out (Multipl  (None, 14, 14, 672)  0          ['stack_4_block4_MB_dw_swish[0][0\n",
      " y)                                                              ]',                              \n",
      "                                                                  'stack_4_block4_se_sigmoid[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " stack_4_block4_MB_pw_conv (Con  (None, 14, 14, 112)  75264      ['stack_4_block4_se_out[0][0]']  \n",
      " v2D)                                                                                             \n",
      "                                                                                                  \n",
      " stack_4_block4_MB_pw_bn (Batch  (None, 14, 14, 112)  448        ['stack_4_block4_MB_pw_conv[0][0]\n",
      " Normalization)                                                  ']                               \n",
      "                                                                                                  \n",
      " stack_4_block4_output (Add)    (None, 14, 14, 112)  0           ['stack_4_block3_output[0][0]',  \n",
      "                                                                  'stack_4_block4_MB_pw_bn[0][0]']\n",
      "                                                                                                  \n",
      " stack_5_block0_sortcut_conv (C  (None, 14, 14, 672)  75264      ['stack_4_block4_output[0][0]']  \n",
      " onv2D)                                                                                           \n",
      "                                                                                                  \n",
      " stack_5_block0_sortcut_bn (Bat  (None, 14, 14, 672)  2688       ['stack_5_block0_sortcut_conv[0][\n",
      " chNormalization)                                                0]']                             \n",
      "                                                                                                  \n",
      " stack_5_block0_sortcut_swish (  (None, 14, 14, 672)  0          ['stack_5_block0_sortcut_bn[0][0]\n",
      " Activation)                                                     ']                               \n",
      "                                                                                                  \n",
      " stack_5_block0_MB_dw_ (Depthwi  (None, 7, 7, 672)   6048        ['stack_5_block0_sortcut_swish[0]\n",
      " seConv2D)                                                       [0]']                            \n",
      "                                                                                                  \n",
      " stack_5_block0_MB_dw_bn (Batch  (None, 7, 7, 672)   2688        ['stack_5_block0_MB_dw_[0][0]']  \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " stack_5_block0_MB_dw_swish (Ac  (None, 7, 7, 672)   0           ['stack_5_block0_MB_dw_bn[0][0]']\n",
      " tivation)                                                                                        \n",
      "                                                                                                  \n",
      " tf.math.reduce_mean_8 (TFOpLam  (None, 1, 1, 672)   0           ['stack_5_block0_MB_dw_swish[0][0\n",
      " bda)                                                            ]']                              \n",
      "                                                                                                  \n",
      " stack_5_block0_se_1_conv (Conv  (None, 1, 1, 28)    18844       ['tf.math.reduce_mean_8[0][0]']  \n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " stack_5_block0_se_swish (Activ  (None, 1, 1, 28)    0           ['stack_5_block0_se_1_conv[0][0]'\n",
      " ation)                                                          ]                                \n",
      "                                                                                                  \n",
      " stack_5_block0_se_2_conv (Conv  (None, 1, 1, 672)   19488       ['stack_5_block0_se_swish[0][0]']\n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " stack_5_block0_se_sigmoid (Act  (None, 1, 1, 672)   0           ['stack_5_block0_se_2_conv[0][0]'\n",
      " ivation)                                                        ]                                \n",
      "                                                                                                  \n",
      " stack_5_block0_se_out (Multipl  (None, 7, 7, 672)   0           ['stack_5_block0_MB_dw_swish[0][0\n",
      " y)                                                              ]',                              \n",
      "                                                                  'stack_5_block0_se_sigmoid[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " stack_5_block0_MB_pw_conv (Con  (None, 7, 7, 192)   129024      ['stack_5_block0_se_out[0][0]']  \n",
      " v2D)                                                                                             \n",
      "                                                                                                  \n",
      " stack_5_block0_MB_pw_bn (Batch  (None, 7, 7, 192)   768         ['stack_5_block0_MB_pw_conv[0][0]\n",
      " Normalization)                                                  ']                               \n",
      "                                                                                                  \n",
      " stack_5_block0_output (Activat  (None, 7, 7, 192)   0           ['stack_5_block0_MB_pw_bn[0][0]']\n",
      " ion)                                                                                             \n",
      "                                                                                                  \n",
      " stack_5_block1_sortcut_conv (C  (None, 7, 7, 1152)  221184      ['stack_5_block0_output[0][0]']  \n",
      " onv2D)                                                                                           \n",
      "                                                                                                  \n",
      " stack_5_block1_sortcut_bn (Bat  (None, 7, 7, 1152)  4608        ['stack_5_block1_sortcut_conv[0][\n",
      " chNormalization)                                                0]']                             \n",
      "                                                                                                  \n",
      " stack_5_block1_sortcut_swish (  (None, 7, 7, 1152)  0           ['stack_5_block1_sortcut_bn[0][0]\n",
      " Activation)                                                     ']                               \n",
      "                                                                                                  \n",
      " stack_5_block1_MB_dw_ (Depthwi  (None, 7, 7, 1152)  10368       ['stack_5_block1_sortcut_swish[0]\n",
      " seConv2D)                                                       [0]']                            \n",
      "                                                                                                  \n",
      " stack_5_block1_MB_dw_bn (Batch  (None, 7, 7, 1152)  4608        ['stack_5_block1_MB_dw_[0][0]']  \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " stack_5_block1_MB_dw_swish (Ac  (None, 7, 7, 1152)  0           ['stack_5_block1_MB_dw_bn[0][0]']\n",
      " tivation)                                                                                        \n",
      "                                                                                                  \n",
      " tf.math.reduce_mean_9 (TFOpLam  (None, 1, 1, 1152)  0           ['stack_5_block1_MB_dw_swish[0][0\n",
      " bda)                                                            ]']                              \n",
      "                                                                                                  \n",
      " stack_5_block1_se_1_conv (Conv  (None, 1, 1, 48)    55344       ['tf.math.reduce_mean_9[0][0]']  \n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " stack_5_block1_se_swish (Activ  (None, 1, 1, 48)    0           ['stack_5_block1_se_1_conv[0][0]'\n",
      " ation)                                                          ]                                \n",
      "                                                                                                  \n",
      " stack_5_block1_se_2_conv (Conv  (None, 1, 1, 1152)  56448       ['stack_5_block1_se_swish[0][0]']\n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " stack_5_block1_se_sigmoid (Act  (None, 1, 1, 1152)  0           ['stack_5_block1_se_2_conv[0][0]'\n",
      " ivation)                                                        ]                                \n",
      "                                                                                                  \n",
      " stack_5_block1_se_out (Multipl  (None, 7, 7, 1152)  0           ['stack_5_block1_MB_dw_swish[0][0\n",
      " y)                                                              ]',                              \n",
      "                                                                  'stack_5_block1_se_sigmoid[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " stack_5_block1_MB_pw_conv (Con  (None, 7, 7, 192)   221184      ['stack_5_block1_se_out[0][0]']  \n",
      " v2D)                                                                                             \n",
      "                                                                                                  \n",
      " stack_5_block1_MB_pw_bn (Batch  (None, 7, 7, 192)   768         ['stack_5_block1_MB_pw_conv[0][0]\n",
      " Normalization)                                                  ']                               \n",
      "                                                                                                  \n",
      " stack_5_block1_output (Add)    (None, 7, 7, 192)    0           ['stack_5_block0_output[0][0]',  \n",
      "                                                                  'stack_5_block1_MB_pw_bn[0][0]']\n",
      "                                                                                                  \n",
      " stack_5_block2_sortcut_conv (C  (None, 7, 7, 1152)  221184      ['stack_5_block1_output[0][0]']  \n",
      " onv2D)                                                                                           \n",
      "                                                                                                  \n",
      " stack_5_block2_sortcut_bn (Bat  (None, 7, 7, 1152)  4608        ['stack_5_block2_sortcut_conv[0][\n",
      " chNormalization)                                                0]']                             \n",
      "                                                                                                  \n",
      " stack_5_block2_sortcut_swish (  (None, 7, 7, 1152)  0           ['stack_5_block2_sortcut_bn[0][0]\n",
      " Activation)                                                     ']                               \n",
      "                                                                                                  \n",
      " stack_5_block2_MB_dw_ (Depthwi  (None, 7, 7, 1152)  10368       ['stack_5_block2_sortcut_swish[0]\n",
      " seConv2D)                                                       [0]']                            \n",
      "                                                                                                  \n",
      " stack_5_block2_MB_dw_bn (Batch  (None, 7, 7, 1152)  4608        ['stack_5_block2_MB_dw_[0][0]']  \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " stack_5_block2_MB_dw_swish (Ac  (None, 7, 7, 1152)  0           ['stack_5_block2_MB_dw_bn[0][0]']\n",
      " tivation)                                                                                        \n",
      "                                                                                                  \n",
      " tf.math.reduce_mean_10 (TFOpLa  (None, 1, 1, 1152)  0           ['stack_5_block2_MB_dw_swish[0][0\n",
      " mbda)                                                           ]']                              \n",
      "                                                                                                  \n",
      " stack_5_block2_se_1_conv (Conv  (None, 1, 1, 48)    55344       ['tf.math.reduce_mean_10[0][0]'] \n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " stack_5_block2_se_swish (Activ  (None, 1, 1, 48)    0           ['stack_5_block2_se_1_conv[0][0]'\n",
      " ation)                                                          ]                                \n",
      "                                                                                                  \n",
      " stack_5_block2_se_2_conv (Conv  (None, 1, 1, 1152)  56448       ['stack_5_block2_se_swish[0][0]']\n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " stack_5_block2_se_sigmoid (Act  (None, 1, 1, 1152)  0           ['stack_5_block2_se_2_conv[0][0]'\n",
      " ivation)                                                        ]                                \n",
      "                                                                                                  \n",
      " stack_5_block2_se_out (Multipl  (None, 7, 7, 1152)  0           ['stack_5_block2_MB_dw_swish[0][0\n",
      " y)                                                              ]',                              \n",
      "                                                                  'stack_5_block2_se_sigmoid[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " stack_5_block2_MB_pw_conv (Con  (None, 7, 7, 192)   221184      ['stack_5_block2_se_out[0][0]']  \n",
      " v2D)                                                                                             \n",
      "                                                                                                  \n",
      " stack_5_block2_MB_pw_bn (Batch  (None, 7, 7, 192)   768         ['stack_5_block2_MB_pw_conv[0][0]\n",
      " Normalization)                                                  ']                               \n",
      "                                                                                                  \n",
      " stack_5_block2_output (Add)    (None, 7, 7, 192)    0           ['stack_5_block1_output[0][0]',  \n",
      "                                                                  'stack_5_block2_MB_pw_bn[0][0]']\n",
      "                                                                                                  \n",
      " stack_5_block3_sortcut_conv (C  (None, 7, 7, 1152)  221184      ['stack_5_block2_output[0][0]']  \n",
      " onv2D)                                                                                           \n",
      "                                                                                                  \n",
      " stack_5_block3_sortcut_bn (Bat  (None, 7, 7, 1152)  4608        ['stack_5_block3_sortcut_conv[0][\n",
      " chNormalization)                                                0]']                             \n",
      "                                                                                                  \n",
      " stack_5_block3_sortcut_swish (  (None, 7, 7, 1152)  0           ['stack_5_block3_sortcut_bn[0][0]\n",
      " Activation)                                                     ']                               \n",
      "                                                                                                  \n",
      " stack_5_block3_MB_dw_ (Depthwi  (None, 7, 7, 1152)  10368       ['stack_5_block3_sortcut_swish[0]\n",
      " seConv2D)                                                       [0]']                            \n",
      "                                                                                                  \n",
      " stack_5_block3_MB_dw_bn (Batch  (None, 7, 7, 1152)  4608        ['stack_5_block3_MB_dw_[0][0]']  \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " stack_5_block3_MB_dw_swish (Ac  (None, 7, 7, 1152)  0           ['stack_5_block3_MB_dw_bn[0][0]']\n",
      " tivation)                                                                                        \n",
      "                                                                                                  \n",
      " tf.math.reduce_mean_11 (TFOpLa  (None, 1, 1, 1152)  0           ['stack_5_block3_MB_dw_swish[0][0\n",
      " mbda)                                                           ]']                              \n",
      "                                                                                                  \n",
      " stack_5_block3_se_1_conv (Conv  (None, 1, 1, 48)    55344       ['tf.math.reduce_mean_11[0][0]'] \n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " stack_5_block3_se_swish (Activ  (None, 1, 1, 48)    0           ['stack_5_block3_se_1_conv[0][0]'\n",
      " ation)                                                          ]                                \n",
      "                                                                                                  \n",
      " stack_5_block3_se_2_conv (Conv  (None, 1, 1, 1152)  56448       ['stack_5_block3_se_swish[0][0]']\n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " stack_5_block3_se_sigmoid (Act  (None, 1, 1, 1152)  0           ['stack_5_block3_se_2_conv[0][0]'\n",
      " ivation)                                                        ]                                \n",
      "                                                                                                  \n",
      " stack_5_block3_se_out (Multipl  (None, 7, 7, 1152)  0           ['stack_5_block3_MB_dw_swish[0][0\n",
      " y)                                                              ]',                              \n",
      "                                                                  'stack_5_block3_se_sigmoid[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " stack_5_block3_MB_pw_conv (Con  (None, 7, 7, 192)   221184      ['stack_5_block3_se_out[0][0]']  \n",
      " v2D)                                                                                             \n",
      "                                                                                                  \n",
      " stack_5_block3_MB_pw_bn (Batch  (None, 7, 7, 192)   768         ['stack_5_block3_MB_pw_conv[0][0]\n",
      " Normalization)                                                  ']                               \n",
      "                                                                                                  \n",
      " stack_5_block3_output (Add)    (None, 7, 7, 192)    0           ['stack_5_block2_output[0][0]',  \n",
      "                                                                  'stack_5_block3_MB_pw_bn[0][0]']\n",
      "                                                                                                  \n",
      " stack_5_block4_sortcut_conv (C  (None, 7, 7, 1152)  221184      ['stack_5_block3_output[0][0]']  \n",
      " onv2D)                                                                                           \n",
      "                                                                                                  \n",
      " stack_5_block4_sortcut_bn (Bat  (None, 7, 7, 1152)  4608        ['stack_5_block4_sortcut_conv[0][\n",
      " chNormalization)                                                0]']                             \n",
      "                                                                                                  \n",
      " stack_5_block4_sortcut_swish (  (None, 7, 7, 1152)  0           ['stack_5_block4_sortcut_bn[0][0]\n",
      " Activation)                                                     ']                               \n",
      "                                                                                                  \n",
      " stack_5_block4_MB_dw_ (Depthwi  (None, 7, 7, 1152)  10368       ['stack_5_block4_sortcut_swish[0]\n",
      " seConv2D)                                                       [0]']                            \n",
      "                                                                                                  \n",
      " stack_5_block4_MB_dw_bn (Batch  (None, 7, 7, 1152)  4608        ['stack_5_block4_MB_dw_[0][0]']  \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " stack_5_block4_MB_dw_swish (Ac  (None, 7, 7, 1152)  0           ['stack_5_block4_MB_dw_bn[0][0]']\n",
      " tivation)                                                                                        \n",
      "                                                                                                  \n",
      " tf.math.reduce_mean_12 (TFOpLa  (None, 1, 1, 1152)  0           ['stack_5_block4_MB_dw_swish[0][0\n",
      " mbda)                                                           ]']                              \n",
      "                                                                                                  \n",
      " stack_5_block4_se_1_conv (Conv  (None, 1, 1, 48)    55344       ['tf.math.reduce_mean_12[0][0]'] \n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " stack_5_block4_se_swish (Activ  (None, 1, 1, 48)    0           ['stack_5_block4_se_1_conv[0][0]'\n",
      " ation)                                                          ]                                \n",
      "                                                                                                  \n",
      " stack_5_block4_se_2_conv (Conv  (None, 1, 1, 1152)  56448       ['stack_5_block4_se_swish[0][0]']\n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " stack_5_block4_se_sigmoid (Act  (None, 1, 1, 1152)  0           ['stack_5_block4_se_2_conv[0][0]'\n",
      " ivation)                                                        ]                                \n",
      "                                                                                                  \n",
      " stack_5_block4_se_out (Multipl  (None, 7, 7, 1152)  0           ['stack_5_block4_MB_dw_swish[0][0\n",
      " y)                                                              ]',                              \n",
      "                                                                  'stack_5_block4_se_sigmoid[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " stack_5_block4_MB_pw_conv (Con  (None, 7, 7, 192)   221184      ['stack_5_block4_se_out[0][0]']  \n",
      " v2D)                                                                                             \n",
      "                                                                                                  \n",
      " stack_5_block4_MB_pw_bn (Batch  (None, 7, 7, 192)   768         ['stack_5_block4_MB_pw_conv[0][0]\n",
      " Normalization)                                                  ']                               \n",
      "                                                                                                  \n",
      " stack_5_block4_output (Add)    (None, 7, 7, 192)    0           ['stack_5_block3_output[0][0]',  \n",
      "                                                                  'stack_5_block4_MB_pw_bn[0][0]']\n",
      "                                                                                                  \n",
      " stack_5_block5_sortcut_conv (C  (None, 7, 7, 1152)  221184      ['stack_5_block4_output[0][0]']  \n",
      " onv2D)                                                                                           \n",
      "                                                                                                  \n",
      " stack_5_block5_sortcut_bn (Bat  (None, 7, 7, 1152)  4608        ['stack_5_block5_sortcut_conv[0][\n",
      " chNormalization)                                                0]']                             \n",
      "                                                                                                  \n",
      " stack_5_block5_sortcut_swish (  (None, 7, 7, 1152)  0           ['stack_5_block5_sortcut_bn[0][0]\n",
      " Activation)                                                     ']                               \n",
      "                                                                                                  \n",
      " stack_5_block5_MB_dw_ (Depthwi  (None, 7, 7, 1152)  10368       ['stack_5_block5_sortcut_swish[0]\n",
      " seConv2D)                                                       [0]']                            \n",
      "                                                                                                  \n",
      " stack_5_block5_MB_dw_bn (Batch  (None, 7, 7, 1152)  4608        ['stack_5_block5_MB_dw_[0][0]']  \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " stack_5_block5_MB_dw_swish (Ac  (None, 7, 7, 1152)  0           ['stack_5_block5_MB_dw_bn[0][0]']\n",
      " tivation)                                                                                        \n",
      "                                                                                                  \n",
      " tf.math.reduce_mean_13 (TFOpLa  (None, 1, 1, 1152)  0           ['stack_5_block5_MB_dw_swish[0][0\n",
      " mbda)                                                           ]']                              \n",
      "                                                                                                  \n",
      " stack_5_block5_se_1_conv (Conv  (None, 1, 1, 48)    55344       ['tf.math.reduce_mean_13[0][0]'] \n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " stack_5_block5_se_swish (Activ  (None, 1, 1, 48)    0           ['stack_5_block5_se_1_conv[0][0]'\n",
      " ation)                                                          ]                                \n",
      "                                                                                                  \n",
      " stack_5_block5_se_2_conv (Conv  (None, 1, 1, 1152)  56448       ['stack_5_block5_se_swish[0][0]']\n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " stack_5_block5_se_sigmoid (Act  (None, 1, 1, 1152)  0           ['stack_5_block5_se_2_conv[0][0]'\n",
      " ivation)                                                        ]                                \n",
      "                                                                                                  \n",
      " stack_5_block5_se_out (Multipl  (None, 7, 7, 1152)  0           ['stack_5_block5_MB_dw_swish[0][0\n",
      " y)                                                              ]',                              \n",
      "                                                                  'stack_5_block5_se_sigmoid[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " stack_5_block5_MB_pw_conv (Con  (None, 7, 7, 192)   221184      ['stack_5_block5_se_out[0][0]']  \n",
      " v2D)                                                                                             \n",
      "                                                                                                  \n",
      " stack_5_block5_MB_pw_bn (Batch  (None, 7, 7, 192)   768         ['stack_5_block5_MB_pw_conv[0][0]\n",
      " Normalization)                                                  ']                               \n",
      "                                                                                                  \n",
      " stack_5_block5_output (Add)    (None, 7, 7, 192)    0           ['stack_5_block4_output[0][0]',  \n",
      "                                                                  'stack_5_block5_MB_pw_bn[0][0]']\n",
      "                                                                                                  \n",
      " stack_5_block6_sortcut_conv (C  (None, 7, 7, 1152)  221184      ['stack_5_block5_output[0][0]']  \n",
      " onv2D)                                                                                           \n",
      "                                                                                                  \n",
      " stack_5_block6_sortcut_bn (Bat  (None, 7, 7, 1152)  4608        ['stack_5_block6_sortcut_conv[0][\n",
      " chNormalization)                                                0]']                             \n",
      "                                                                                                  \n",
      " stack_5_block6_sortcut_swish (  (None, 7, 7, 1152)  0           ['stack_5_block6_sortcut_bn[0][0]\n",
      " Activation)                                                     ']                               \n",
      "                                                                                                  \n",
      " stack_5_block6_MB_dw_ (Depthwi  (None, 7, 7, 1152)  10368       ['stack_5_block6_sortcut_swish[0]\n",
      " seConv2D)                                                       [0]']                            \n",
      "                                                                                                  \n",
      " stack_5_block6_MB_dw_bn (Batch  (None, 7, 7, 1152)  4608        ['stack_5_block6_MB_dw_[0][0]']  \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " stack_5_block6_MB_dw_swish (Ac  (None, 7, 7, 1152)  0           ['stack_5_block6_MB_dw_bn[0][0]']\n",
      " tivation)                                                                                        \n",
      "                                                                                                  \n",
      " tf.math.reduce_mean_14 (TFOpLa  (None, 1, 1, 1152)  0           ['stack_5_block6_MB_dw_swish[0][0\n",
      " mbda)                                                           ]']                              \n",
      "                                                                                                  \n",
      " stack_5_block6_se_1_conv (Conv  (None, 1, 1, 48)    55344       ['tf.math.reduce_mean_14[0][0]'] \n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " stack_5_block6_se_swish (Activ  (None, 1, 1, 48)    0           ['stack_5_block6_se_1_conv[0][0]'\n",
      " ation)                                                          ]                                \n",
      "                                                                                                  \n",
      " stack_5_block6_se_2_conv (Conv  (None, 1, 1, 1152)  56448       ['stack_5_block6_se_swish[0][0]']\n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " stack_5_block6_se_sigmoid (Act  (None, 1, 1, 1152)  0           ['stack_5_block6_se_2_conv[0][0]'\n",
      " ivation)                                                        ]                                \n",
      "                                                                                                  \n",
      " stack_5_block6_se_out (Multipl  (None, 7, 7, 1152)  0           ['stack_5_block6_MB_dw_swish[0][0\n",
      " y)                                                              ]',                              \n",
      "                                                                  'stack_5_block6_se_sigmoid[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " stack_5_block6_MB_pw_conv (Con  (None, 7, 7, 192)   221184      ['stack_5_block6_se_out[0][0]']  \n",
      " v2D)                                                                                             \n",
      "                                                                                                  \n",
      " stack_5_block6_MB_pw_bn (Batch  (None, 7, 7, 192)   768         ['stack_5_block6_MB_pw_conv[0][0]\n",
      " Normalization)                                                  ']                               \n",
      "                                                                                                  \n",
      " stack_5_block6_output (Add)    (None, 7, 7, 192)    0           ['stack_5_block5_output[0][0]',  \n",
      "                                                                  'stack_5_block6_MB_pw_bn[0][0]']\n",
      "                                                                                                  \n",
      " stack_5_block7_sortcut_conv (C  (None, 7, 7, 1152)  221184      ['stack_5_block6_output[0][0]']  \n",
      " onv2D)                                                                                           \n",
      "                                                                                                  \n",
      " stack_5_block7_sortcut_bn (Bat  (None, 7, 7, 1152)  4608        ['stack_5_block7_sortcut_conv[0][\n",
      " chNormalization)                                                0]']                             \n",
      "                                                                                                  \n",
      " stack_5_block7_sortcut_swish (  (None, 7, 7, 1152)  0           ['stack_5_block7_sortcut_bn[0][0]\n",
      " Activation)                                                     ']                               \n",
      "                                                                                                  \n",
      " stack_5_block7_MB_dw_ (Depthwi  (None, 7, 7, 1152)  10368       ['stack_5_block7_sortcut_swish[0]\n",
      " seConv2D)                                                       [0]']                            \n",
      "                                                                                                  \n",
      " stack_5_block7_MB_dw_bn (Batch  (None, 7, 7, 1152)  4608        ['stack_5_block7_MB_dw_[0][0]']  \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " stack_5_block7_MB_dw_swish (Ac  (None, 7, 7, 1152)  0           ['stack_5_block7_MB_dw_bn[0][0]']\n",
      " tivation)                                                                                        \n",
      "                                                                                                  \n",
      " tf.math.reduce_mean_15 (TFOpLa  (None, 1, 1, 1152)  0           ['stack_5_block7_MB_dw_swish[0][0\n",
      " mbda)                                                           ]']                              \n",
      "                                                                                                  \n",
      " stack_5_block7_se_1_conv (Conv  (None, 1, 1, 48)    55344       ['tf.math.reduce_mean_15[0][0]'] \n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " stack_5_block7_se_swish (Activ  (None, 1, 1, 48)    0           ['stack_5_block7_se_1_conv[0][0]'\n",
      " ation)                                                          ]                                \n",
      "                                                                                                  \n",
      " stack_5_block7_se_2_conv (Conv  (None, 1, 1, 1152)  56448       ['stack_5_block7_se_swish[0][0]']\n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " stack_5_block7_se_sigmoid (Act  (None, 1, 1, 1152)  0           ['stack_5_block7_se_2_conv[0][0]'\n",
      " ivation)                                                        ]                                \n",
      "                                                                                                  \n",
      " stack_5_block7_se_out (Multipl  (None, 7, 7, 1152)  0           ['stack_5_block7_MB_dw_swish[0][0\n",
      " y)                                                              ]',                              \n",
      "                                                                  'stack_5_block7_se_sigmoid[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " stack_5_block7_MB_pw_conv (Con  (None, 7, 7, 192)   221184      ['stack_5_block7_se_out[0][0]']  \n",
      " v2D)                                                                                             \n",
      "                                                                                                  \n",
      " stack_5_block7_MB_pw_bn (Batch  (None, 7, 7, 192)   768         ['stack_5_block7_MB_pw_conv[0][0]\n",
      " Normalization)                                                  ']                               \n",
      "                                                                                                  \n",
      " stack_5_block7_output (Add)    (None, 7, 7, 192)    0           ['stack_5_block6_output[0][0]',  \n",
      "                                                                  'stack_5_block7_MB_pw_bn[0][0]']\n",
      "                                                                                                  \n",
      " post_conv (Conv2D)             (None, 7, 7, 1280)   245760      ['stack_5_block7_output[0][0]']  \n",
      "                                                                                                  \n",
      " post_bn (BatchNormalization)   (None, 7, 7, 1280)   5120        ['post_conv[0][0]']              \n",
      "                                                                                                  \n",
      " post_swish (Activation)        (None, 7, 7, 1280)   0           ['post_bn[0][0]']                \n",
      "                                                                                                  \n",
      " avg_pool (GlobalAveragePooling  (None, 1280)        0           ['post_swish[0][0]']             \n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " head_drop (Dropout)            (None, 1280)         0           ['avg_pool[0][0]']               \n",
      "                                                                                                  \n",
      " predictions (Dense)            (None, 10)           12810       ['head_drop[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 5,932,122\n",
      "Trainable params: 5,871,514\n",
      "Non-trainable params: 60,608\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Will download and load `imagenet` pretrained weights.\n",
    "# Model weight is loaded with `by_name=True, skip_mismatch=True`.\n",
    "# include_preprocessing set True will add pre-processing Rescale + Normalization after Input. \n",
    "# Means using input value in range [0, 255]. Default value False means in range [-1, 1].\n",
    "\n",
    "from keras_cv_attention_models import efficientnet\n",
    "#model3 = efficientnet.EfficientNetV2B0(pretrained=\"imagenet\", include_preprocessing=True) # value in range [0, 255]\n",
    "#model2 = efficientnet.EfficientNetV2B0(pretrained=\"imagenet\") # values in range [-1, 1]\n",
    "#model = keras.models.load_model(\"/home/local/lambda/rishabhs/ML/keras_cv_attention_models/checkpoints_bkup_finetunedcifar10\")\n",
    "pretrained = os.path.expanduser('/home/local/lambda/rishabhs/ML/keras_cv_attention_models/checkpoints_bkup_finetunedcifar10/effv2b0_cifar10_224_progressive_epoch_35_val_acc_0.9528.h5')\n",
    "model = efficientnet.EfficientNetV2B0(pretrained=pretrained, input_shape=(224, 224, 3), num_classes=10, classifier_activation='softmax', dropout=0.1)\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-06 22:21:33.337293: I tensorflow/stream_executor/cuda/cuda_dnn.cc:368] Loaded cuDNN version 8100\n"
     ]
    }
   ],
   "source": [
    "\"\"\" Run predict \"\"\"\n",
    "from skimage.data import chelsea\n",
    "\n",
    "# Run prediction\n",
    "# Needs preprocessing\n",
    "imm = tf.image.resize(chelsea(), model.input_shape[1:3]) # Chelsea the cat\n",
    "pred = model(tf.expand_dims(imm / 128. - 1., 0)).numpy()\n",
    "#pred = model(tf.expand_dims(imm, 0)).numpy()\n",
    "#print('model', keras.applications.efficientnet_v2.decode_predictions(pred)[0])\n",
    "\n",
    "# img = chelsea() # Chelsea the cat\n",
    "# imm = keras.applications.imagenet_utils.preprocess_input(img, mode='torch') # preprocesses the data to [-1, 1]\n",
    "# pred2 = model2(tf.expand_dims(tf.image.resize(imm, model2.input_shape[1:3]), 0)).numpy()\n",
    "# print('model2', keras.applications.imagenet_utils.decode_predictions(pred2)[0])\n",
    "\n",
    "# # imm = tf.image.resize(chelsea(), model3.input_shape[1:3]) # Chelsea the cat\n",
    "# # pred = model(tf.expand_dims(imm, 0)).numpy()  # value in range [0, 255]\n",
    "# img = chelsea() # Chelsea the cat\n",
    "# pred3 = model3(tf.expand_dims(tf.image.resize(img, model3.input_shape[1:3]), 0)).numpy()\n",
    "# print('model3', keras.applications.imagenet_utils.decode_predictions(pred3)[0])\n",
    "\n",
    "# #pred = tf.nn.softmax(pred).numpy()\n",
    "# #pred = model(tf.expand_dims(imm / 128. - 1., 0)).numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/local/lambda/rishabhs/anaconda3/envs/cloned_tf2.8-cudnn8.1-cudadev-11.2-py3.8/lib/\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "echo $LD_LIBRARY_PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-06 22:21:50.264748: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-04-06 22:21:50.728449: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 46255 MB memory:  -> device: 0, name: Quadro RTX 8000, pci bus id: 0000:68:00.0, compute capability: 7.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>>> Using input_shape (224, 224) for Keras model.\n",
      ">>>> rescale_mode: torch\n",
      ">i>>> Dataset args: {'data_name': 'cifar10', 'batch_size': 64, 'buffer_size': 1000, 'info_only': False, 'rescale_mode': 'torch', 'random_crop_min': 1.0, 'random_erasing_prob': 0.0, 'magnitude': 0, 'num_layers': 2, 'augment_kwargs': {}, 'cutmix_alpha': 0, 'eval_central_crop': 0.875, 'input_shape': (224, 224), 'mixup_alpha': 0, 'resize_antialias': True, 'resize_method': 'bicubic'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:   0%|          | 0/157 [00:00<?, ?it/s]2022-04-06 22:21:53.661372: I tensorflow/stream_executor/cuda/cuda_dnn.cc:368] Loaded cuDNN version 8100\n",
      "Evaluating: 100%|██████████| 157/157 [00:18<00:00,  8.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>>> Accuracy top1: 0.9524 top5: 0.9987\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "CUDA_VISIBLE_DEVICES='3,4' python ./eval_script.py -m ./checkpoints/effv2b0_cifar10_224_progressive_epoch_35_val_acc_0.9528.h5 --central_crop 0.875 -d cifar10 \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Another try to use full integer quant with 8uint Input/output\n",
    "### Original model is such that it expects inputs in range [-1, 1] (include_preprocessing = False)\n",
    "* Representative dataset should be also in range [-1, 1]\n",
    "* Need to make sure rescale mode for cifar10 is torch. \n",
    "#### rescale_mode torch means (image - [0.485, 0.456, 0.406]) / [[0.229, 0.224, 0.225]], tf means (image - 0.5) / 0.5.\n",
    "* Make sure resize method is bicubic.\n",
    "#### data.initdataset actually gives output in range [-1, 1] but need to specify rescale mode and resize method.\n",
    "#### Hence it is understandable why bad idea to use 8int along with this data representation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "#import pandas as pd\n",
    "#import matplotlib.pyplot as plt\n",
    "from tensorflow import keras\n",
    "from keras_cv_attention_models import efficientnet\n",
    "\n",
    "from keras_cv_attention_models import regnet, model_surgery\n",
    "from keras_cv_attention_models.imagenet import eval_func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from keras_cv_attention_models.imagenet import data\n",
    "\n",
    "def representative_dataset_gen():\n",
    "    train_dataset, _, _, _, _ = data.init_dataset(data_name='cifar10', input_shape=model.input_shape[1:], batch_size=1,\n",
    "                                                  rescale_mode='tf', resize_method='bicubic', eval_central_crop=0.875)\n",
    "    aa = train_dataset.as_numpy_iterator()\n",
    "    for _ in range(500):\n",
    "        # Get sample input data as a numpy array in a method of your choosing.\n",
    "        # It's `[]` wrapped image input with batch_size 1, like `[np.ones([1, 224, 224, 3])]`.\n",
    "        yield [aa.next()[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-06 22:22:19.302113: W tensorflow/python/util/util.cc:368] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmp_ax0vx8f/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/local/lambda/rishabhs/anaconda3/envs/cloned_tf2.8-cudnn8.1-cudadev-11.2-py3.8/lib/python3.8/site-packages/tensorflow/lite/python/convert.py:746: UserWarning: Statistics for quantized inputs were expected, but not specified; continuing anyway.\n",
      "  warnings.warn(\"Statistics for quantized inputs were expected, but not \"\n",
      "2022-04-06 22:22:48.578386: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:357] Ignored output_format.\n",
      "2022-04-06 22:22:48.578409: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:360] Ignored drop_control_dependency.\n",
      "2022-04-06 22:22:48.579487: I tensorflow/cc/saved_model/reader.cc:43] Reading SavedModel from: /tmp/tmp_ax0vx8f\n",
      "2022-04-06 22:22:48.628054: I tensorflow/cc/saved_model/reader.cc:78] Reading meta graph with tags { serve }\n",
      "2022-04-06 22:22:48.628082: I tensorflow/cc/saved_model/reader.cc:119] Reading SavedModel debug info (if present) from: /tmp/tmp_ax0vx8f\n",
      "2022-04-06 22:22:48.847815: I tensorflow/cc/saved_model/loader.cc:228] Restoring SavedModel bundle.\n",
      "2022-04-06 22:22:49.626829: I tensorflow/cc/saved_model/loader.cc:212] Running initialization op on SavedModel bundle at path: /tmp/tmp_ax0vx8f\n",
      "2022-04-06 22:22:50.000309: I tensorflow/cc/saved_model/loader.cc:301] SavedModel load for tags { serve }; Status: success: OK. Took 1420825 microseconds.\n",
      "2022-04-06 22:22:50.834096: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:237] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">i>>> Dataset args: {'data_name': 'cifar10', 'batch_size': 1, 'buffer_size': 1000, 'info_only': False, 'rescale_mode': 'tf', 'random_crop_min': 1.0, 'random_erasing_prob': 0.0, 'magnitude': 0, 'num_layers': 2, 'augment_kwargs': {}, 'cutmix_alpha': 0, 'eval_central_crop': 0.875, 'input_shape': (224, 224, 3), 'mixup_alpha': 0, 'resize_antialias': False, 'resize_method': 'bicubic'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-06 22:24:34.595011: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "fully_quantize: 0, inference_type: 6, input_inference_type: 3, output_inference_type: 3\n",
      "WARNING:absl:Buffer deduplication procedure will be skipped when flatbuffer library is not properly loaded\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "# Here I am only using any conv2d to split conv2d surgery before converting the model into quantized one\n",
    "cc = model_surgery.convert_groups_conv2d_2_split_conv2d(model)  # converts all `Conv2D` using `groups` to `SplitConv2D`\n",
    "#mm = model\n",
    "test_inputs = np.random.uniform(size=[1, *cc.input_shape[1:]])\n",
    "print(np.allclose(cc(test_inputs), model(test_inputs)))\n",
    "# True\n",
    "\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(cc)\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT] # quantizes weights\n",
    "converter.representative_dataset = representative_dataset_gen\n",
    "# Ensure that if any ops can't be quantized, the converter throws an error\n",
    "converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n",
    "# Set the input and output tensors to uint8 (APIs added in r2.3)\n",
    "converter.inference_input_type = tf.uint8\n",
    "converter.inference_output_type = tf.uint8\n",
    "open(cc.name + \"_splconv2d_uint8.tflite\", \"wb\").write(converter.convert())\n",
    "\n",
    "print(np.allclose(cc(test_inputs), eval_func.TFLiteModelInterf(cc.name + '_splconv2d_uint8.tflite')(test_inputs), atol=1e-3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input:  <class 'numpy.uint8'>\n",
      "output:  <class 'numpy.uint8'>\n"
     ]
    }
   ],
   "source": [
    "tflite_models_dir= \"/home/local/lambda/rishabhs/ML/keras_cv_attention_models/cifar10_tflite_models/\"\n",
    "tflite_model_quant= tflite_models_dir + \"efficientnet_v2-b0_splconv2d_uint8.tflite\"\n",
    "\n",
    "interpreter = tf.lite.Interpreter(model_path=str(tflite_model_quant))\n",
    "input_type = interpreter.get_input_details()[0]['dtype']\n",
    "print('input: ', input_type)\n",
    "output_type = interpreter.get_output_details()[0]['dtype']\n",
    "print('output: ', output_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "try:\n",
    "  # Disable first two GPUs\n",
    "  tf.config.set_visible_devices(physical_devices[2:], 'GPU')\n",
    "  logical_devices = tf.config.list_logical_devices('GPU')\n",
    "  # Logical device was not created for first GPU\n",
    "  assert len(logical_devices) == len(physical_devices) - 2\n",
    "except:\n",
    "  # Invalid device or cannot modify virtual devices once initialized.\n",
    "  pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-06 22:40:24.482004: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-04-06 22:40:24.952872: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 46255 MB memory:  -> device: 0, name: Quadro RTX 8000, pci bus id: 0000:68:00.0, compute capability: 7.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>>> Using input_shape [224, 224] for TFLite model.\n",
      ">>>> rescale_mode: torch\n",
      ">i>>> Dataset args: {'data_name': 'cifar10', 'batch_size': 64, 'buffer_size': 1000, 'info_only': False, 'rescale_mode': 'torch', 'random_crop_min': 1.0, 'random_erasing_prob': 0.0, 'magnitude': 0, 'num_layers': 2, 'augment_kwargs': {}, 'cutmix_alpha': 0, 'eval_central_crop': 0.875, 'input_shape': [224, 224], 'mixup_alpha': 0, 'resize_antialias': True, 'resize_method': 'bicubic'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Evaluating:   0%|          | 0/157 [00:00<?, ?it/s]\r",
      "Evaluating:   1%|          | 1/157 [01:41<4:22:50, 101.09s/it]\r",
      "Evaluating:   1%|▏         | 2/157 [03:20<4:18:14, 99.96s/it] \r",
      "Evaluating:   2%|▏         | 3/157 [04:59<4:15:42, 99.62s/it]\r",
      "Evaluating:   3%|▎         | 4/157 [06:38<4:13:40, 99.48s/it]\r",
      "Evaluating:   3%|▎         | 5/157 [08:18<4:12:30, 99.67s/it]\r",
      "Evaluating:   4%|▍         | 6/157 [10:02<4:14:43, 101.22s/it]\r",
      "Evaluating:   4%|▍         | 7/157 [11:48<4:16:14, 102.50s/it]\r",
      "Evaluating:   5%|▌         | 8/157 [13:33<4:17:09, 103.55s/it]\r",
      "Evaluating:   6%|▌         | 9/157 [15:17<4:15:50, 103.72s/it]\r",
      "Evaluating:   6%|▋         | 10/157 [17:02<4:14:40, 103.95s/it]\r",
      "Evaluating:   7%|▋         | 11/157 [18:47<4:13:45, 104.29s/it]\r",
      "Evaluating:   8%|▊         | 12/157 [20:42<4:19:39, 107.45s/it]\r",
      "Evaluating:   8%|▊         | 13/157 [22:36<4:22:59, 109.58s/it]\r",
      "Evaluating:   9%|▉         | 14/157 [24:30<4:24:33, 111.00s/it]\r",
      "Evaluating:  10%|▉         | 15/157 [26:25<4:24:55, 111.94s/it]\r",
      "Evaluating:  10%|█         | 16/157 [28:19<4:24:32, 112.57s/it]\r",
      "Evaluating:  11%|█         | 17/157 [30:13<4:24:05, 113.19s/it]\r",
      "Evaluating:  11%|█▏        | 18/157 [32:01<4:18:42, 111.67s/it]\r",
      "Evaluating:  12%|█▏        | 19/157 [33:47<4:12:19, 109.71s/it]\r",
      "Evaluating:  13%|█▎        | 20/157 [35:33<4:07:59, 108.61s/it]\r",
      "Evaluating:  13%|█▎        | 21/157 [37:17<4:03:22, 107.37s/it]\r",
      "Evaluating:  14%|█▍        | 22/157 [39:02<4:00:10, 106.75s/it]\r",
      "Evaluating:  15%|█▍        | 23/157 [40:47<3:57:04, 106.15s/it]\r",
      "Evaluating:  15%|█▌        | 24/157 [42:33<3:54:55, 105.98s/it]\r",
      "Evaluating:  16%|█▌        | 25/157 [44:18<3:52:51, 105.85s/it]\r",
      "Evaluating:  17%|█▋        | 26/157 [46:03<3:50:40, 105.65s/it]\r",
      "Evaluating:  17%|█▋        | 27/157 [47:47<3:47:46, 105.13s/it]\r",
      "Evaluating:  18%|█▊        | 28/157 [49:32<3:45:58, 105.10s/it]\r",
      "Evaluating:  18%|█▊        | 29/157 [51:17<3:44:04, 105.04s/it]\r",
      "Evaluating:  19%|█▉        | 30/157 [53:02<3:42:10, 104.96s/it]\r",
      "Evaluating:  20%|█▉        | 31/157 [54:44<3:38:29, 104.05s/it]\r",
      "Evaluating:  20%|██        | 32/157 [56:26<3:35:45, 103.57s/it]\r",
      "Evaluating:  21%|██        | 33/157 [58:07<3:32:29, 102.82s/it]\r",
      "Evaluating:  22%|██▏       | 34/157 [59:50<3:30:26, 102.65s/it]\r",
      "Evaluating:  22%|██▏       | 35/157 [1:01:32<3:28:36, 102.60s/it]\r",
      "Evaluating:  23%|██▎       | 36/157 [1:03:12<3:25:23, 101.85s/it]\r",
      "Evaluating:  24%|██▎       | 37/157 [1:04:53<3:23:13, 101.61s/it]\r",
      "Evaluating:  24%|██▍       | 38/157 [1:06:37<3:22:43, 102.21s/it]\r",
      "Evaluating:  25%|██▍       | 39/157 [1:08:32<3:28:32, 106.04s/it]\r",
      "Evaluating:  25%|██▌       | 40/157 [1:10:27<3:31:59, 108.71s/it]\r",
      "Evaluating:  26%|██▌       | 41/157 [1:12:18<3:31:49, 109.57s/it]\r",
      "Evaluating:  27%|██▋       | 42/157 [1:14:01<3:25:55, 107.44s/it]\r",
      "Evaluating:  27%|██▋       | 43/157 [1:15:45<3:22:04, 106.35s/it]\r",
      "Evaluating:  28%|██▊       | 44/157 [1:17:30<3:19:25, 105.89s/it]\r",
      "Evaluating:  29%|██▊       | 45/157 [1:19:12<3:15:43, 104.86s/it]\r",
      "Evaluating:  29%|██▉       | 46/157 [1:20:54<3:12:09, 103.87s/it]\r",
      "Evaluating:  30%|██▉       | 47/157 [1:22:33<3:08:00, 102.55s/it]\r",
      "Evaluating:  31%|███       | 48/157 [1:24:13<3:04:44, 101.69s/it]\r",
      "Evaluating:  31%|███       | 49/157 [1:25:53<3:02:01, 101.12s/it]\r",
      "Evaluating:  32%|███▏      | 50/157 [1:27:32<2:59:34, 100.70s/it]\r",
      "Evaluating:  32%|███▏      | 51/157 [1:29:12<2:57:12, 100.31s/it]\r",
      "Evaluating:  33%|███▎      | 52/157 [1:30:51<2:54:59, 99.99s/it] \r",
      "Evaluating:  34%|███▍      | 53/157 [1:32:30<2:53:01, 99.82s/it]\r",
      "Evaluating:  34%|███▍      | 54/157 [1:34:10<2:51:12, 99.74s/it]\r",
      "Evaluating:  35%|███▌      | 55/157 [1:35:49<2:49:18, 99.60s/it]\r",
      "Evaluating:  36%|███▌      | 56/157 [1:37:28<2:47:31, 99.52s/it]\r",
      "Evaluating:  36%|███▋      | 57/157 [1:39:08<2:45:42, 99.43s/it]\r",
      "Evaluating:  37%|███▋      | 58/157 [1:40:47<2:44:07, 99.47s/it]\r",
      "Evaluating:  38%|███▊      | 59/157 [1:42:27<2:42:26, 99.45s/it]\r",
      "Evaluating:  38%|███▊      | 60/157 [1:44:06<2:40:41, 99.39s/it]\r",
      "Evaluating:  39%|███▉      | 61/157 [1:45:45<2:38:54, 99.31s/it]\r",
      "Evaluating:  39%|███▉      | 62/157 [1:47:25<2:37:21, 99.38s/it]\r",
      "Evaluating:  40%|████      | 63/157 [1:49:04<2:35:33, 99.29s/it]\r",
      "Evaluating:  41%|████      | 64/157 [1:50:43<2:34:01, 99.37s/it]\r",
      "Evaluating:  41%|████▏     | 65/157 [1:52:22<2:32:10, 99.24s/it]\r",
      "Evaluating:  42%|████▏     | 66/157 [1:54:02<2:30:43, 99.37s/it]\r",
      "Evaluating:  43%|████▎     | 67/157 [1:55:41<2:29:00, 99.34s/it]\r",
      "Evaluating:  43%|████▎     | 68/157 [1:57:22<2:27:50, 99.66s/it]\r",
      "Evaluating:  44%|████▍     | 69/157 [1:59:02<2:26:43, 100.04s/it]\r",
      "Evaluating:  45%|████▍     | 70/157 [2:00:44<2:25:50, 100.58s/it]\r",
      "Evaluating:  45%|████▌     | 71/157 [2:02:24<2:23:43, 100.27s/it]\r",
      "Evaluating:  46%|████▌     | 72/157 [2:04:03<2:21:45, 100.07s/it]\r",
      "Evaluating:  46%|████▋     | 73/157 [2:05:43<2:19:47, 99.85s/it] \r",
      "Evaluating:  47%|████▋     | 74/157 [2:07:23<2:18:21, 100.01s/it]\r",
      "Evaluating:  48%|████▊     | 75/157 [2:09:03<2:16:41, 100.02s/it]\r",
      "Evaluating:  48%|████▊     | 76/157 [2:10:44<2:15:21, 100.26s/it]\r",
      "Evaluating:  49%|████▉     | 77/157 [2:12:24<2:13:26, 100.08s/it]\r",
      "Evaluating:  50%|████▉     | 78/157 [2:14:03<2:11:28, 99.85s/it] \r",
      "Evaluating:  50%|█████     | 79/157 [2:15:44<2:10:14, 100.18s/it]\r",
      "Evaluating:  51%|█████     | 80/157 [2:17:24<2:08:35, 100.20s/it]\r",
      "Evaluating:  52%|█████▏    | 81/157 [2:19:05<2:07:08, 100.38s/it]\r",
      "Evaluating:  52%|█████▏    | 82/157 [2:20:45<2:05:27, 100.37s/it]\r",
      "Evaluating:  53%|█████▎    | 83/157 [2:22:27<2:04:12, 100.71s/it]\r",
      "Evaluating:  54%|█████▎    | 84/157 [2:24:07<2:02:16, 100.50s/it]\r",
      "Evaluating:  54%|█████▍    | 85/157 [2:25:46<2:00:12, 100.17s/it]\r",
      "Evaluating:  55%|█████▍    | 86/157 [2:27:26<1:58:14, 99.93s/it] \r",
      "Evaluating:  55%|█████▌    | 87/157 [2:29:05<1:56:23, 99.76s/it]\r",
      "Evaluating:  56%|█████▌    | 88/157 [2:30:45<1:54:49, 99.84s/it]\r",
      "Evaluating:  57%|█████▋    | 89/157 [2:32:25<1:53:12, 99.89s/it]\r",
      "Evaluating:  57%|█████▋    | 90/157 [2:34:07<1:52:08, 100.42s/it]\r",
      "Evaluating:  58%|█████▊    | 91/157 [2:35:46<1:50:03, 100.06s/it]\r",
      "Evaluating:  59%|█████▊    | 92/157 [2:37:25<1:47:58, 99.66s/it] \r",
      "Evaluating:  59%|█████▉    | 93/157 [2:39:04<1:46:06, 99.48s/it]\r",
      "Evaluating:  60%|█████▉    | 94/157 [2:40:44<1:44:49, 99.83s/it]\r",
      "Evaluating:  61%|██████    | 95/157 [2:42:23<1:42:57, 99.64s/it]\r",
      "Evaluating:  61%|██████    | 96/157 [2:44:03<1:41:21, 99.69s/it]\r",
      "Evaluating:  62%|██████▏   | 97/157 [2:45:42<1:39:21, 99.35s/it]\r",
      "Evaluating:  62%|██████▏   | 98/157 [2:47:20<1:37:21, 99.02s/it]\r",
      "Evaluating:  63%|██████▎   | 99/157 [2:48:58<1:35:28, 98.77s/it]\r",
      "Evaluating:  64%|██████▎   | 100/157 [2:50:36<1:33:37, 98.56s/it]\r",
      "Evaluating:  64%|██████▍   | 101/157 [2:52:15<1:31:58, 98.54s/it]\r",
      "Evaluating:  65%|██████▍   | 102/157 [2:53:53<1:30:18, 98.52s/it]\r",
      "Evaluating:  66%|██████▌   | 103/157 [2:55:32<1:28:44, 98.61s/it]\r",
      "Evaluating:  66%|██████▌   | 104/157 [2:57:17<1:28:51, 100.59s/it]\r",
      "Evaluating:  67%|██████▋   | 105/157 [2:59:12<1:30:57, 104.95s/it]\r",
      "Evaluating:  68%|██████▊   | 106/157 [3:01:07<1:31:31, 107.68s/it]\r",
      "Evaluating:  68%|██████▊   | 107/157 [3:03:02<1:31:35, 109.92s/it]\r",
      "Evaluating:  69%|██████▉   | 108/157 [3:04:56<1:30:49, 111.21s/it]\r",
      "Evaluating:  69%|██████▉   | 109/157 [3:06:50<1:29:32, 111.93s/it]\r",
      "Evaluating:  70%|███████   | 110/157 [3:08:43<1:28:04, 112.43s/it]\r",
      "Evaluating:  71%|███████   | 111/157 [3:10:36<1:26:24, 112.70s/it]\r",
      "Evaluating:  71%|███████▏  | 112/157 [3:12:30<1:24:41, 112.92s/it]\r",
      "Evaluating:  72%|███████▏  | 113/157 [3:14:23<1:22:55, 113.09s/it]\r",
      "Evaluating:  73%|███████▎  | 114/157 [3:16:17<1:21:09, 113.23s/it]\r",
      "Evaluating:  73%|███████▎  | 115/157 [3:18:10<1:19:16, 113.25s/it]\r",
      "Evaluating:  74%|███████▍  | 116/157 [3:20:04<1:17:27, 113.35s/it]\r",
      "Evaluating:  75%|███████▍  | 117/157 [3:21:57<1:15:34, 113.37s/it]\r",
      "Evaluating:  75%|███████▌  | 118/157 [3:23:51<1:13:41, 113.38s/it]\r",
      "Evaluating:  76%|███████▌  | 119/157 [3:25:45<1:11:56, 113.58s/it]\r",
      "Evaluating:  76%|███████▋  | 120/157 [3:27:39<1:10:08, 113.75s/it]\r",
      "Evaluating:  77%|███████▋  | 121/157 [3:29:32<1:08:12, 113.69s/it]\r",
      "Evaluating:  78%|███████▊  | 122/157 [3:31:26<1:06:23, 113.82s/it]\r",
      "Evaluating:  78%|███████▊  | 123/157 [3:33:21<1:04:41, 114.15s/it]\r",
      "Evaluating:  79%|███████▉  | 124/157 [3:35:15<1:02:43, 114.05s/it]\r",
      "Evaluating:  80%|███████▉  | 125/157 [3:37:09<1:00:43, 113.87s/it]\r",
      "Evaluating:  80%|████████  | 126/157 [3:39:02<58:45, 113.72s/it]  \r",
      "Evaluating:  81%|████████  | 127/157 [3:40:55<56:49, 113.64s/it]\r",
      "Evaluating:  82%|████████▏ | 128/157 [3:42:49<54:54, 113.59s/it]\r",
      "Evaluating:  82%|████████▏ | 129/157 [3:44:42<52:59, 113.57s/it]\r",
      "Evaluating:  83%|████████▎ | 130/157 [3:46:36<51:03, 113.45s/it]\r",
      "Evaluating:  83%|████████▎ | 131/157 [3:48:29<49:08, 113.39s/it]\r",
      "Evaluating:  84%|████████▍ | 132/157 [3:50:23<47:20, 113.62s/it]\r",
      "Evaluating:  85%|████████▍ | 133/157 [3:52:17<45:26, 113.59s/it]\r",
      "Evaluating:  85%|████████▌ | 134/157 [3:54:10<43:32, 113.60s/it]\r",
      "Evaluating:  86%|████████▌ | 135/157 [3:56:04<41:38, 113.56s/it]\r",
      "Evaluating:  87%|████████▋ | 136/157 [3:57:57<39:43, 113.50s/it]\r",
      "Evaluating:  87%|████████▋ | 137/157 [3:59:50<37:49, 113.48s/it]\r",
      "Evaluating:  88%|████████▊ | 138/157 [4:01:44<35:55, 113.47s/it]\r",
      "Evaluating:  89%|████████▊ | 139/157 [4:03:37<34:02, 113.49s/it]\r",
      "Evaluating:  89%|████████▉ | 140/157 [4:05:31<32:09, 113.50s/it]\r",
      "Evaluating:  90%|████████▉ | 141/157 [4:07:25<30:16, 113.54s/it]\r",
      "Evaluating:  90%|█████████ | 142/157 [4:09:18<28:21, 113.45s/it]\r",
      "Evaluating:  91%|█████████ | 143/157 [4:11:11<26:28, 113.49s/it]\r",
      "Evaluating:  92%|█████████▏| 144/157 [4:13:05<24:34, 113.40s/it]\r",
      "Evaluating:  92%|█████████▏| 145/157 [4:14:58<22:42, 113.54s/it]\r",
      "Evaluating:  93%|█████████▎| 146/157 [4:16:52<20:48, 113.53s/it]\r",
      "Evaluating:  94%|█████████▎| 147/157 [4:18:46<18:55, 113.54s/it]\r",
      "Evaluating:  94%|█████████▍| 148/157 [4:20:40<17:03, 113.71s/it]\r",
      "Evaluating:  95%|█████████▍| 149/157 [4:22:33<15:09, 113.69s/it]\r",
      "Evaluating:  96%|█████████▌| 150/157 [4:24:27<13:14, 113.56s/it]\r",
      "Evaluating:  96%|█████████▌| 151/157 [4:26:20<11:21, 113.60s/it]\r",
      "Evaluating:  97%|█████████▋| 152/157 [4:28:13<09:27, 113.48s/it]\r",
      "Evaluating:  97%|█████████▋| 153/157 [4:30:07<07:34, 113.55s/it]\r",
      "Evaluating:  98%|█████████▊| 154/157 [4:32:01<05:40, 113.49s/it]\r",
      "Evaluating:  99%|█████████▊| 155/157 [4:33:54<03:46, 113.40s/it]\r",
      "Evaluating:  99%|█████████▉| 156/157 [4:35:47<01:53, 113.40s/it]\r",
      "Evaluating: 100%|██████████| 157/157 [4:36:15<00:00, 87.88s/it] \r",
      "Evaluating: 100%|██████████| 157/157 [4:36:15<00:00, 105.58s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>>> Accuracy top1: 0.8758 top5: 0.9915\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "CUDA_VISIBLE_DEVICES=3,4 python ./eval_script.py -m ./efficientnet_v2-b0_splconv2d_uint8.tflite --central_crop 0.875 -d cifar10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert using float fallback quantization\n",
    "\n",
    "To quantize the variable data (such as model input/output and intermediates between layers), you need to provide a RepresentativeDataset. This is a generator function that provides a set of input data that's large enough to represent typical values. It allows the converter to estimate a dynamic range for all the variable data. (The dataset does not need to be unique compared to the training or evaluation dataset.) To support multiple inputs, each representative data point is a list and elements in the list are fed to the model according to their indices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpwcbis2y0/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpwcbis2y0/assets\n",
      "/home/local/lambda/rishabhs/anaconda3/envs/cloned_tf2.8-cudnn8.1-cudadev-11.2-py3.8/lib/python3.8/site-packages/tensorflow/lite/python/convert.py:746: UserWarning: Statistics for quantized inputs were expected, but not specified; continuing anyway.\n",
      "  warnings.warn(\"Statistics for quantized inputs were expected, but not \"\n",
      "2022-04-07 15:28:26.746297: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:357] Ignored output_format.\n",
      "2022-04-07 15:28:26.746327: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:360] Ignored drop_control_dependency.\n",
      "2022-04-07 15:28:26.746561: I tensorflow/cc/saved_model/reader.cc:43] Reading SavedModel from: /tmp/tmpwcbis2y0\n",
      "2022-04-07 15:28:26.791419: I tensorflow/cc/saved_model/reader.cc:78] Reading meta graph with tags { serve }\n",
      "2022-04-07 15:28:26.791447: I tensorflow/cc/saved_model/reader.cc:119] Reading SavedModel debug info (if present) from: /tmp/tmpwcbis2y0\n",
      "2022-04-07 15:28:26.987756: I tensorflow/cc/saved_model/loader.cc:228] Restoring SavedModel bundle.\n",
      "2022-04-07 15:28:27.712461: I tensorflow/cc/saved_model/loader.cc:212] Running initialization op on SavedModel bundle at path: /tmp/tmpwcbis2y0\n",
      "2022-04-07 15:28:28.086492: I tensorflow/cc/saved_model/loader.cc:301] SavedModel load for tags { serve }; Status: success: OK. Took 1339932 microseconds.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">i>>> Dataset args: {'data_name': 'cifar10', 'batch_size': 1, 'buffer_size': 1000, 'info_only': False, 'rescale_mode': 'tf', 'random_crop_min': 1.0, 'random_erasing_prob': 0.0, 'magnitude': 0, 'num_layers': 2, 'augment_kwargs': {}, 'cutmix_alpha': 0, 'eval_central_crop': 0.875, 'input_shape': (224, 224, 3), 'mixup_alpha': 0, 'resize_antialias': False, 'resize_method': 'bicubic'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-07 15:30:09.170883: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "fully_quantize: 0, inference_type: 6, input_inference_type: 0, output_inference_type: 0\n",
      "WARNING:absl:Buffer deduplication procedure will be skipped when flatbuffer library is not properly loaded\n",
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "converter = tf.lite.TFLiteConverter.from_keras_model(cc)\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "converter.representative_dataset = representative_dataset_gen\n",
    "open(cc.name + \"_splconv2d_dynquant_floatfallback.tflite\", \"wb\").write(converter.convert())\n",
    "\n",
    "print(np.allclose(cc(test_inputs), eval_func.TFLiteModelInterf(cc.name + '_splconv2d_dynquant_floatfallback.tflite')(test_inputs), atol=1e-3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input:  <class 'numpy.float32'>\n",
      "output:  <class 'numpy.float32'>\n"
     ]
    }
   ],
   "source": [
    "tflite_models_dir= \"/home/local/lambda/rishabhs/ML/keras_cv_attention_models/cifar10_tflite_models/\"\n",
    "tflite_model_quant= tflite_models_dir + \"efficientnet_v2-b0_splconv2d_dynquant_floatfallback.tflite\"\n",
    "\n",
    "interpreter = tf.lite.Interpreter(model_path=str(tflite_model_quant))\n",
    "input_type = interpreter.get_input_details()[0]['dtype']\n",
    "print('input: ', input_type)\n",
    "output_type = interpreter.get_output_details()[0]['dtype']\n",
    "print('output: ', output_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "try:\n",
    "  # Disable first two GPUs\n",
    "  tf.config.set_visible_devices(physical_devices[2:], 'GPU')\n",
    "  logical_devices = tf.config.list_logical_devices('GPU')\n",
    "  # Logical device was not created for first GPU\n",
    "  assert len(logical_devices) == len(physical_devices) - 2\n",
    "except:\n",
    "  # Invalid device or cannot modify virtual devices once initialized.\n",
    "  pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "2022-04-07 15:31:34.559216: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-04-07 15:31:35.023975: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 46580 MB memory:  -> device: 0, name: Quadro RTX 8000, pci bus id: 0000:68:00.0, compute capability: 7.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>>> Using input_shape [224, 224] for TFLite model.\n",
      ">>>> rescale_mode: torch\n",
      ">i>>> Dataset args: {'data_name': 'cifar10', 'batch_size': 64, 'buffer_size': 1000, 'info_only': False, 'rescale_mode': 'torch', 'random_crop_min': 1.0, 'random_erasing_prob': 0.0, 'magnitude': 0, 'num_layers': 2, 'augment_kwargs': {}, 'cutmix_alpha': 0, 'eval_central_crop': 0.875, 'input_shape': [224, 224], 'mixup_alpha': 0, 'resize_antialias': True, 'resize_method': 'bicubic'}\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "CUDA_VISIBLE_DEVICES=3,4 python ./eval_script.py -m ./efficientnet_v2-b0_splconv2d_dynquant_floatfallback.tflite --central_crop 0.875 -d cifar10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conv2d to Split Conv2d\n",
    "* Once the model is converted the new model outputs for a set of inputs is compared with the original model outputs.\n",
    "\n",
    "### Model converted to a TFLite model (No quantization done)\n",
    "* Again the converted the model outputs for a set of inputs is compared with the Split Conv2d model.\n",
    "\n",
    "### Is split conv2d really necessary?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from keras_cv_attention_models import regnet, model_surgery\n",
    "from keras_cv_attention_models.imagenet import eval_func\n",
    "\n",
    "mm = model_surgery.convert_groups_conv2d_2_split_conv2d(model)  # converts all `Conv2D` using `groups` to `SplitConv2D`\n",
    "#mm = model\n",
    "test_inputs = np.random.uniform(size=[1, *mm.input_shape[1:]])\n",
    "print(np.allclose(mm(test_inputs), model(test_inputs)))\n",
    "# True\n",
    "\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(mm)\n",
    "open(mm.name + \"_no_quant.tflite\", \"wb\").write(converter.convert())\n",
    "print(np.allclose(mm(test_inputs), eval_func.TFLiteModelInterf(mm.name + '_no_quant.tflite')(test_inputs), atol=1e-7))\n",
    "# True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy top1: 0.9523 top5: 0.9987\n",
    "* CUDA_VISIBLE_DEVICES='1,2,3,4' python ./eval_script.py -m ./efficientnet_v2-b0_no_quant.tflite --central_crop 0.875 -d cifar10 \n",
    "* 23 MB efficientnet_v2-b0_no_quant.tflite "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "CUDA_VISIBLE_DEVICES='1,2,3,4' python ./eval_script.py -m ./efficientnet_v2-b0_no_quant.tflite --central_crop 0.875 -d cifar10 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Need to use representative dataset for uint quantization\n",
    "* Make sure that try with only conv2d to split conv2d operation done\n",
    "* Performed both the operations here conv2d to split conv2d and other gelu one which probably messed up the model acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from keras_cv_attention_models.imagenet import data\n",
    "\n",
    "def representative_dataset2():\n",
    "  for data in tf.data.Dataset.from_tensor_slices((images)).batch(1).take(100):\n",
    "    yield [tf.dtypes.cast(data, tf.float32)]\n",
    "    \n",
    "def representative_dataset():\n",
    "    for _ in range(100):\n",
    "      data = np.random.rand(1, 224, 224, 3)\n",
    "      yield [data.astype(np.float32)]\n",
    "        \n",
    "def representative_dataset_gen():\n",
    "    train_dataset, _, _, _, _ = data.init_dataset(data_name='cifar10', input_shape=mm.input_shape[1:], batch_size=1)\n",
    "    aa = train_dataset.as_numpy_iterator()\n",
    "    for _ in range(100):\n",
    "        # Get sample input data as a numpy array in a method of your choosing.\n",
    "        # It's `[]` wrapped image input with batch_size 1, like `[np.ones([1, 224, 224, 3])]`.\n",
    "        yield [aa.next()[0]]\n",
    " \n",
    "mm = model_surgery.prepare_for_tflite(model)\n",
    "print(np.allclose(mm(test_inputs), model(test_inputs)))\n",
    "# True\n",
    "\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(mm)\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT] # quantizes weights\n",
    "converter.representative_dataset = representative_dataset_gen\n",
    "converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n",
    "converter.inference_input_type = tf.int8\n",
    "converter.inference_output_type = tf.int8\n",
    "open(mm.name + \"_int8.tflite\", \"wb\").write(converter.convert())\n",
    "# 30M regnetzd32_uint8.tflite\n",
    "print(np.allclose(mm(test_inputs), eval_func.TFLiteModelInterf(mm.name + '_int8.tflite')(test_inputs), atol=1e-3))\n",
    "# True\n",
    "\n",
    "# converter = tf.lite.TFLiteConverter.from_keras_model(mm)\n",
    "# converter.optimizations = [tf.lite.Optimize.DEFAULT] # quantizes weights\n",
    "# converter.representative_dataset = representative_dataset \n",
    "# converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n",
    "# converter.inference_input_type = tf.uint8  # or tf.uint8\n",
    "# converter.inference_output_type = tf.int8  # or tf.uint8\n",
    "\n",
    "# open(mm.name + \"_wt8int_act8uint_v3.tflite\", \"wb\").write(converter.convert())\n",
    "# print(np.allclose(mm(test_inputs), eval_func.TFLiteModelInterf(mm.name + '_wt8int_act8uint_v3.tflite')(test_inputs), atol=1e-7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tflite_models_dir= \"/home/local/lambda/rishabhs/ML/keras_cv_attention_models/cifar10_tflite_models/\"\n",
    "tflite_model_quant= tflite_models_dir + \"efficientnet_v2-b0_int8.tflite\"\n",
    "\n",
    "interpreter = tf.lite.Interpreter(model_path=str(tflite_model_quant))\n",
    "input_type = interpreter.get_input_details()[0]['dtype']\n",
    "print('input: ', input_type)\n",
    "output_type = interpreter.get_output_details()[0]['dtype']\n",
    "print('output: ', output_type)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy top1: 0.1 top5: 0.4999 8INT\n",
    "This is with signed INT. UINT is much better\n",
    "### Accuracy top1: 0.8697 top5: 0.992 8UINT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "CUDA_VISIBLE_DEVICES='1,2,3,4' python ./eval_script.py -m ./efficientnet_v2-b0_int8.tflite --central_crop 0.875 -d cifar10 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conv2d to Split Conv2d\n",
    "* Once the model is converted the new model outputs for a set of inputs is compared with the original model outputs. (bb)\n",
    "\n",
    "### Model converted to a TFLite model (8uint quantization done) weights are 8int\n",
    "* Again the converted the model outputs for a set of inputs is compared with the Split Conv2d model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Here I am only using any conv2d to split conv2d surgery before converting the model into quantized one\n",
    "bb = model_surgery.convert_groups_conv2d_2_split_conv2d(model)  # converts all `Conv2D` using `groups` to `SplitConv2D`\n",
    "#mm = model\n",
    "test_inputs = np.random.uniform(size=[1, *bb.input_shape[1:]])\n",
    "print(np.allclose(bb(test_inputs), model(test_inputs)))\n",
    "# True\n",
    "\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(bb)\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT] # quantizes weights\n",
    "converter.representative_dataset = representative_dataset_gen\n",
    "# Ensure that if any ops can't be quantized, the converter throws an error\n",
    "converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n",
    "# Set the input and output tensors to uint8 (APIs added in r2.3)\n",
    "converter.inference_input_type = tf.uint8\n",
    "converter.inference_output_type = tf.uint8\n",
    "open(bb.name + \"_nosurg_uint8.tflite\", \"wb\").write(converter.convert())\n",
    "# 30M regnetzd32_uint8.tflite\n",
    "print(np.allclose(bb(test_inputs), eval_func.TFLiteModelInterf(bb.name + '_nosurg_uint8.tflite')(test_inputs), atol=1e-3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tflite_models_dir= \"/home/local/lambda/rishabhs/ML/keras_cv_attention_models/cifar10_tflite_models/\"\n",
    "tflite_model_quant= tflite_models_dir + \"efficientnet_v2-b0_nosurg_uint8.tflite\"\n",
    "\n",
    "interpreter = tf.lite.Interpreter(model_path=str(tflite_model_quant))\n",
    "input_type = interpreter.get_input_details()[0]['dtype']\n",
    "print('input: ', input_type)\n",
    "output_type = interpreter.get_output_details()[0]['dtype']\n",
    "print('output: ', output_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "CUDA_VISIBLE_DEVICES='1,2,3,4' python ./eval_script.py -m ./efficientnet_v2-b0_nosurg_uint8.tflite --central_crop 0.875 -d cifar10 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## JUNK CODE BELOW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)\n",
    "#from keras_cv_attention_models.efficientnet import progressive_train_test\n",
    "#os.environ['CUDA_VISIBLE_DEVICES'] = '3'\n",
    "os.environ['TF_XLA_FLAGS'] = \"--tf_xla_auto_jit=2\"\n",
    "\n",
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!python progressive_train_script.py \\\n",
    "-m efficientnet.EfficientNetV2B0 --summary --pretrained imagenet -d cifar10 --lr_decay_steps 36 -s effv2b0_preprocTrue_cifar10_224_progressive \\\n",
    "--progressive_epochs 10 20 30 -1 \\\n",
    "--progressive_input_shapes 128 160 192 224 \\\n",
    "--progressive_dropouts 0.1 0.2 0.3 0.4 \\\n",
    "--progressive_magnitudes 5 8 12 15 \\\n",
    "--progressive_batch_sizes 240 \\\n",
    "--seed 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "CUDA_VISIBLE_DEVICES='3' TF_XLA_FLAGS=\"--tf_xla_auto_jit=2\" python ./progressive_train_script.py \\\n",
    "-m efficientnet.EfficientNetV2B0 --pretrained imagenet -d cifar10 --lr_decay_steps 36 -s effv2b0_cifar10_224_progressive \\\n",
    "--progressive_epochs 10 20 30 -1 \\\n",
    "--progressive_input_shapes 128 160 192 224 \\\n",
    "--progressive_dropouts 0.1 0.2 0.3 0.4 \\\n",
    "--progressive_magnitudes 5 8 12 15 \\\n",
    "--progressive_batch_sizes 240 \\\n",
    "--seed 0"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cloned_tf2.8-cudnn8.1-cudadev-11.2-py3.8",
   "language": "python",
   "name": "cloned_tf2.8-cudnn8.1-cudadev-11.2-py3.8"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
